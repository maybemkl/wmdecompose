{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from flow_wmd.utils import *\n",
    "from gensim.models import Word2Vec \n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 17.8 s, total: 2min 42s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "PATH = \"../data/yelp_dataset/\"\n",
    "yelp_data = []\n",
    "r_dtypes = {\"review_id\":str,\n",
    "            \"user_id\":str,\n",
    "            \"business_id\":str,\n",
    "            \"stars\": np.int32, \n",
    "            \"date\":str,\n",
    "            \"text\":str,\n",
    "            \"useful\": np.int32, \n",
    "            \"funny\": np.int32,\n",
    "            \"cool\": np.int32}\n",
    "drop = ['review_id', 'user_id', 'business_id','stars','date','useful', 'funny', 'cool']\n",
    "\n",
    "with open(f\"{PATH}yelp_academic_dataset_review.json\", \"r\") as f:\n",
    "    reader = pd.read_json(f, orient=\"records\", lines=True, dtype=r_dtypes, chunksize=1000)\n",
    "    for chunk in reader:\n",
    "        reduced_chunk = chunk.drop(columns=drop)\n",
    "        yelp_data.append(reduced_chunk)\n",
    "    \n",
    "yelp_data = pd.concat(yelp_data, ignore_index=True)\n",
    "\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = yelp_data.text.astype('str').tolist()\n",
    "tokenizer = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentences_clean=[remove_stopwords(r, stopword_list, tokenizer) for r in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentences_clean=pd.Series(sentences_clean).apply(denoise_text)\n",
    "sentences_clean=sentences_clean.apply(remove_special_characters)\n",
    "sentences_clean=sentences_clean.apply(simple_lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sentences_clean=[remove_stopwords(r, stopword_list, tokenizer) for r in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tokenized = [w.lower() for w in sentences_clean]\n",
    "sentences_tokenized = [tokenizer.tokenize(i) for i in sentences_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading GoogleNews Vectors\")\n",
    "%time model = KeyedVectors.load_word2vec_format('../embeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Phrase Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHRASING = True\n",
    "MIN = 10\n",
    "THRESHOLD = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 11.7 s, total: 1min 45s\n",
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "if PHRASING:\n",
    "    sentences_phrased = get_phrases(sentences_tokenized, \n",
    "                                    min_count = MIN, \n",
    "                                    threshold = THRESHOLD)\n",
    "    sentences_training = sentences_phrased\n",
    "    \n",
    "else:\n",
    "    sentences_training = sentences_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'reviewer_mentioned', 'watching', 'oz', 'episode', 'hooked', 'right', 'exactly_happened', 'first', 'thing', 'struck', 'oz', 'brutality', 'unflinching', 'scene', 'violence', 'set', 'right', 'word', 'go', 'trust', 'show', 'faint_hearted', 'timid', 'show', 'pull_punch', 'regard', 'drug', 'sex_violence', 'hardcore', 'classic', 'use_word', 'called', 'oz', 'nickname', 'given', 'oswald', 'maximum_security', 'state', 'penitentary', 'focus_mainly', 'emerald_city', 'experimental', 'section', 'prison_cell', 'glass', 'front', 'face', 'inwards', 'privacy', 'high', 'agenda', 'em', 'city', 'home', 'many', 'aryan', 'muslim', 'gangsta', 'latino', 'christian', 'italian', 'irish', 'scuffle', 'death', 'stare', 'dodgy', 'dealing', 'shady', 'agreement', 'never', 'far_away', 'would', 'say', 'main', 'appeal', 'show', 'due_fact', 'go', 'show', 'dare', 'forget', 'pretty', 'picture', 'painted', 'mainstream_audience', 'forget', 'charm', 'forget', 'romance', 'oz', 'mess', 'around', 'first', 'episode', 'ever', 'saw', 'struck', 'nasty', 'surreal', 'say', 'ready', 'watched', 'developed', 'taste', 'oz', 'got', 'accustomed', 'high_level', 'graphic_violence', 'violence', 'injustice', 'crooked', 'guard', 'sold', 'nickel', 'inmate', 'kill', 'order', 'get', 'away', 'well', 'mannered', 'middle_class', 'inmate', 'turned', 'prison', 'bitch', 'due_lack', 'street', 'skill', 'prison', 'experience', 'watching', 'oz', 'may', 'become', 'comfortable', 'uncomfortable', 'viewing', 'thats', 'get', 'touch', 'darker_side']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_training[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finetune Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Initialize Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to log information about training'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Epoch {self.epoch} starting.\")\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print(f\"Epoch {self.epoch} ended.\")\n",
    "        self.epoch += 1\n",
    "        \n",
    "class LossLogger(CallbackAny2Vec):\n",
    "    '''Output loss at each epoch'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f'Epoch: {self.epoch}', end='\\t')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch != 1:\n",
    "            previous_loss = self.losses[self.epoch-2]\n",
    "        else:\n",
    "            previous_loss = 0\n",
    "        self.losses.append(loss)\n",
    "        difference = loss-previous_loss\n",
    "        print(f'  Loss: {loss}  Difference: {difference}')\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_logger = EpochLogger()\n",
    "loss_logger = LossLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = model.vector_size\n",
    "WINDOW = 10\n",
    "EPOCHS = 4\n",
    "MIN_COUNT = 2\n",
    "SG = 1\n",
    "HS = 0\n",
    "SEED = 42\n",
    "LOSS = True\n",
    "ALPHA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.12 s, sys: 381 ms, total: 6.5 s\n",
      "Wall time: 6.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_ft = Word2Vec(vector_size= SIZE, \n",
    "                    window = WINDOW,\n",
    "                    min_count= MIN_COUNT,\n",
    "                    epochs=EPOCHS,\n",
    "                    sg = SG,\n",
    "                    hs = HS,\n",
    "                    seed = SEED)\n",
    "model_ft.build_vocab(sentences_training)\n",
    "total_examples = model_ft.corpus_count\n",
    "model_ft.build_vocab([list(model.key_to_index.keys())], update=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Train Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"../embeddings/yelp_w2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t  Loss: 34382252.0  Difference: 34382252.0\n",
      "Epoch: 2\t  Loss: 50387232.0  Difference: 16004980.0\n",
      "Epoch: 3\t  Loss: 66620860.0  Difference: 16233628.0\n",
      "Epoch: 4\t  Loss: 67109536.0  Difference: 488676.0\n",
      "CPU times: user 8min, sys: 4.31 s, total: 8min 4s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_ft.train(sentences_training, \n",
    "               total_examples=total_examples,\n",
    "               epochs=model_ft.epochs,\n",
    "               callbacks=[loss_logger],\n",
    "               compute_loss=LOSS,\n",
    "               start_alpha = ALPHA)\n",
    "model_ft.wv.save_word2vec_format(f\"{outfile}.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Load Finetuned Vectors and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vectors = gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(f\"{outfile}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45544904470443726"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_vectors.distance(\"citizen\", \"kane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9603805989027023"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distance(\"citizen\", \"kane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29060083627700806"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_vectors.distance(\"lord\", \"ring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7185895442962646"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.distance(\"lord\", \"ring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03295106, -0.10795593, -0.10198571,  0.00111192,  0.00233896,\n",
       "       -0.06005668,  0.10686377,  0.03378343, -0.08767647,  0.02884012],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_vectors.get_vector(\"citizen_kane\")[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-fwmd",
   "language": "python",
   "name": "venv-fwmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
