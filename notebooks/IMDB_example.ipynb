{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from flow_wmd.documents import Document\n",
    "from flow_wmd.models import LC_RWMD, WMD, WMDManyToMany\n",
    "from flow_wmd.utils import *\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import islice\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare IMDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\"\n",
    "imdb_data = pd.read_csv(f\"{PATH}IMDB_Dataset.csv\")\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Remove special formatting and stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords before denoising, lemmatizing and removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 s, sys: 223 ms, total: 35.7 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tokenizer=ToktokTokenizer()\n",
    "imdb_data['review_clean']= [remove_stopwords(r, stopword_list, tokenizer) for r in imdb_data['review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise, remove special characters, lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 192 ms, total: 25 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(denoise_text)\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(remove_special_characters)\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(simple_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords again, after other preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 67.1 ms, total: 19.8 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "imdb_data['review_clean']= [remove_stopwords(r, stopword_list, tokenizer) for r in imdb_data['review_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data _before_ preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data _after_ preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['review_clean'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Separate pos and neg reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = imdb_data[imdb_data.sentiment == \"positive\"].reset_index(drop=True)\n",
    "neg = imdb_data[imdb_data.sentiment == \"negative\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos.review_clean.tolist()\n",
    "neg = neg.review_clean.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize and \"sample\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tok = list(map(lambda x: tokenize(x, tokenizer), pos[:500]))\n",
    "neg_tok = list(map(lambda x: tokenize(x, tokenizer), neg[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample = [\" \".join(doc) for doc in pos_tok]\n",
    "neg_sample = [\" \".join(doc) for doc in neg_tok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load pretrained Google News W2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GoogleNews Vectors finetuned using IMDB review data.\n",
      "CPU times: user 18.9 s, sys: 273 ms, total: 19.2 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "if not finetuned:\n",
    "    print(\"Loading GoogleNews Vectors\")\n",
    "    %time model = KeyedVectors.load_word2vec_format('../embeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "else:\n",
    "    print(\"Loading GoogleNews Vectors finetuned using IMDB review data.\")\n",
    "    %time model = KeyedVectors.load_word2vec_format('../embeddings/imdb_w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load corpus and remove OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 21 µs\n",
      "CPU times: user 241 ms, sys: 5.27 ms, total: 246 ms\n",
      "Wall time: 247 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(norm='l1',\n",
       "                tokenizer=<function tfidf_tokenize at 0x7ff61fd320d0>,\n",
       "                use_idf=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pos_sample + neg_sample\n",
    "\n",
    "%time vectorizer = TfidfVectorizer(use_idf=False, tokenizer=tfidf_tokenize, norm='l1')\n",
    "%time vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 439 µs, total: 12.5 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time oov = [word for word in vectorizer.get_feature_names() if word not in model.key_to_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 6.75 ms, total: 1.51 s\n",
      "Wall time: 1.52 s\n",
      "CPU times: user 1.4 s, sys: 5.97 ms, total: 1.4 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%time pos_sample = list(map(lambda x: remove_oov(x, tokenizer, oov), pos_sample[:500]))\n",
    "%time neg_sample = list(map(lambda x: remove_oov(x, tokenizer, oov), neg_sample[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 0 ns, total: 23 µs\n",
      "Wall time: 26 µs\n",
      "CPU times: user 227 ms, sys: 3.78 ms, total: 231 ms\n",
      "Wall time: 230 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(norm='l1',\n",
       "                tokenizer=<function tfidf_tokenize at 0x7ff61fd320d0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pos_sample + neg_sample\n",
    "\n",
    "%time vectorizer = TfidfVectorizer(use_idf=True, tokenizer=tfidf_tokenize,norm='l1')\n",
    "%time vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pos_nbow = vectorizer.transform(pos_sample)\n",
    "neg_nbow = vectorizer.transform(neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tok = list(map(lambda x: tokenize(x, tokenizer), pos_sample[:500]))\n",
    "neg_tok =list(map(lambda x: tokenize(x, tokenizer), neg_sample[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewer',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scene',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tok[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 539 µs, total: 15.2 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time oov_ = [word for word in vectorizer.get_feature_names() if word not in model.key_to_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get features and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "idx2word = {idx: word for idx, word in enumerate(vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embedding matrix \"E\" for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.vstack([model.get_vector(word) for word in vectorizer.get_feature_names()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the results of the WMD model more interpretable, we add the option to inspect the output not only by individual words, but also by *word clusters*. We do this by clustering the input words with Kmeans and assigning each word to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the embeddings for the words that are in our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we select the number of clusters we want, initialize the Kmeans model and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "Sum_of_squared_distances = []\n",
    "K = range(5,105, 5)\n",
    "for k in K:\n",
    "    print(k)\n",
    "    km = cluster.KMeans(n_clusters=k)\n",
    "    km = km.fit(X)\n",
    "    Sum_of_squared_distances.append((k,km.inertia_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=100)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLUSTERS = 100\n",
    "kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS, verbose=0)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign labels and centroids to separate variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an index that maps each word to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2cluster = {features[idx]: cl for idx, cl in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('`', 60), ('aaargh', 60), ('aamir', 60), ('aaron', 81), ('ab', 1), ('abandon', 10), ('abandoned', 0), ('abba', 60), ('abbey', 68), ('abbot', 18)]\n"
     ]
    }
   ],
   "source": [
    "print(take(10, word2cluster.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, conversely, create an index that maps each cluster to a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2words = defaultdict(list)\n",
    "for key, value in word2cluster.items():\n",
    "    cluster2words[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'abused', 'accosted', 'alive', 'amputated', 'asleep', 'assassinated', 'attacked', 'avenge', 'beaten', 'beheading', 'belonging', 'bitten', 'blinded', 'blindfolded', 'bloodstained', 'bombed', 'brutally', 'buried', 'burned', 'burnt', 'butchered', 'castrated', 'chained', 'chased', 'confronted', 'crushed', 'cursed', 'dead', 'deposed', 'desecrated', 'die', 'died', 'disarmed', 'disfigured', 'drowned', 'dumped', 'fatally', 'fired', 'fled', 'flee', 'fleeing', 'flogged', 'foiled', 'freed', 'grazed', 'gunned', 'gunning', 'hacked', 'hanged', 'harassed', 'harassing', 'hazed', 'hijacked', 'holed', 'hospitalized', 'hostage', 'hunted', 'infected', 'injured', 'kidnapped', 'kill', 'killed', 'killing', 'lynch', 'manhandled', 'menaced', 'misbehaving', 'missing', 'murdered', 'mutilate', 'mutilated', 'overthrown', 'poisoned', 'punished', 'raided', 'rampaged', 'raped', 'repelled', 'rescued', 'revenge', 'rob', 'robbed', 'semiconscious', 'severed', 'slain', 'slept', 'slit', 'stabbed', 'starving', 'stole', 'stolen', 'stoned', 'stranded', 'strangled', 'strangling', 'taunted', 'terrorized', 'tortured', 'torturing']\n"
     ]
    }
   ],
   "source": [
    "print(cluster2words[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Initialize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all reviews into \"documents\", each with a set of weights per word in the corpus (\"nbow\"), the sum of these weights (\"weights_sum\"), the indeces of the words in the documents (\"idxs\") and the word vectors corresponding to each word (\"vecs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13737 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 131 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pos_docs, neg_docs = [], []\n",
    "\n",
    "for idx, doc in enumerate(pos_tok):\n",
    "    pos_docs.append(Document(doc, pos_nbow[idx], word2idx, E))\n",
    "    \n",
    "for idx, doc in enumerate(neg_tok):\n",
    "    neg_docs.append(Document(doc, neg_nbow[idx], word2idx, E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].nbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12299, 9740, 1036, 2071, 10266, 5148, 13342, 13344, 11302, 5673]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].idxs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16992188,  0.04907227,  0.08154297,  0.12011719, -0.14746094,\n",
       "        0.0291748 ,  0.36523438, -0.10107422,  0.125     ,  0.04516602],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].vecs[:1][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Linear-Complexity Relaxed WMD (LC-RWMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the [Linear-Complexity Relaxed WMD](https://arxiv.org/abs/1711.07227) to get the distances between all positive and all negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 606 µs, sys: 1.03 ms, total: 1.63 ms\n",
      "Wall time: 4.21 ms\n",
      "CPU times: user 2min 15s, sys: 22.3 s, total: 2min 37s\n",
      "Wall time: 41.4 s\n"
     ]
    }
   ],
   "source": [
    "%time lc_rwmd = LC_RWMD(pos_docs, neg_docs,pos_nbow,neg_nbow,E)\n",
    "%time lc_rwmd.get_D()\n",
    "#%time lc_rwmd.get_L(1)\n",
    "#%time lc_rwmd.get_rwmd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Gale-Shapeley Pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [Gale-Shapeley matching algorithm](https://en.wikipedia.org/wiki/Gale%E2%80%93Shapley_algorithm) to find the optimal pairs between positive and negative reviews. This iterates over all the reviews and finds the set of matches that pairs each review with its optimal match given that all positive reviews have to be matched with a negative review and vice versa. The output is a dictionary of key-value pairs, where each pair represents an optimal match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_wmd.gale_shapeley import Matcher\n",
    "\n",
    "matcher = Matcher(lc_rwmd.D)\n",
    "engaged = matcher.matchmaker()\n",
    "matcher.check()\n",
    "pairs = engaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of Gale-Shapeley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(137, 497),\n",
       " (388, 468),\n",
       " (95, 360),\n",
       " (454, 361),\n",
       " (259, 363),\n",
       " (263, 146),\n",
       " (143, 90),\n",
       " (224, 107),\n",
       " (91, 108),\n",
       " (443, 347)]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, pairs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Pairwise WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the pairwise distances between the documents selected by the Galey-Shapeley algorithm _without_ returning the flow between individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated distances between 0 documents.\n",
      "Calculated distances between 100 documents.\n",
      "Calculated distances between 200 documents.\n",
      "Calculated distances between 300 documents.\n",
      "Calculated distances between 400 documents.\n",
      "CPU times: user 4min 10s, sys: 16.1 s, total: 4min 26s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "from flow_wmd.models import WMDPairs\n",
    "\n",
    "wmd_pairs = WMDPairs(pos_docs,neg_docs,pairs,E,idx2word)\n",
    "%time wmd_pairs.get_distances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value is a matrix of distances between the document pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd_pairs.distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the pairwise distances between the documents selected by the Galey-Shapeley algorithm, this time also returning the flow between individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated distances between 0 documents.\n",
      "Calculated distances between 100 documents.\n",
      "Calculated distances between 200 documents.\n",
      "Calculated distances between 300 documents.\n",
      "Calculated distances between 400 documents.\n",
      "CPU times: user 4min 40s, sys: 17.2 s, total: 4min 57s\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "wmd_pairs_flow = WMDPairs(pos_docs,neg_docs,pairs,E,idx2word)\n",
    "%time wmd_pairs_flow.get_distances(return_flow = True, sum_clusters = True, w2c = word2cluster, c2w = cluster2words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three return values.\n",
    "\n",
    "The first one is again a matrix of distances between the document pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd_pairs_flow.distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second return value is a list of tuples with all the words that contributed the most to the distance from the positive documents to the negative ones. These are _not_ sorted from high to low or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exploration', 0.049010000000000005),\n",
       " ('double', 0.18775),\n",
       " ('delinquency', 0.20461),\n",
       " ('distortion', 0.11278),\n",
       " ('pet', 0.24564),\n",
       " ('granddaughter', 0.1211),\n",
       " ('hubris', 0.03926),\n",
       " ('hardened', 0.04453),\n",
       " ('sleeker', 0.03),\n",
       " ('pu', 0.02374)]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.wc_X1.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third return value is a list of tuples with all the words that contributed the most to the distance from the negative documents to the positive ones. Again, these are _not_ sorted from high to low or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('double', 0.12838),\n",
       " ('pet', 0.16274000000000002),\n",
       " ('hardened', 0.07715),\n",
       " ('lurch', 0.0698),\n",
       " ('underwear', 0.02577),\n",
       " ('corpse', 0.026479999999999997),\n",
       " ('primeval', 0.043500000000000004),\n",
       " ('threesome', 0.10307999999999999),\n",
       " ('skate', 0.15538),\n",
       " ('ritualistic', 0.06027)]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.wc_X2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 23.696899999999985),\n",
       " (81, 39.47520000000002),\n",
       " (1, 16.666900000000005),\n",
       " (10, 37.608569999999965),\n",
       " (0, 7.430600000000002),\n",
       " (68, 6.140189999999999),\n",
       " (18, 8.9413),\n",
       " (90, 21.92162),\n",
       " (92, 8.460380000000004),\n",
       " (19, 6.029949999999999)]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.cc_X1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(60, 17.831660000000003),\n",
       " (81, 22.719140000000017),\n",
       " (1, 15.736809999999993),\n",
       " (10, 35.36103999999994),\n",
       " (0, 11.203750000000003),\n",
       " (68, 3.5156499999999995),\n",
       " (18, 10.151929999999995),\n",
       " (90, 24.523450000000004),\n",
       " (92, 10.510490000000006),\n",
       " (19, 7.159270000000002)]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.cc_X2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{36: 89.03332999999994,\n",
       " 62: 84.44415999999983,\n",
       " 48: 44.972770000000025,\n",
       " 81: 39.47520000000002,\n",
       " 10: 37.608569999999965,\n",
       " 27: 32.46946,\n",
       " 52: 32.33321000000001,\n",
       " 58: 32.24520000000002,\n",
       " 75: 31.084949999999996,\n",
       " 25: 30.576999999999995}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.cc_X1.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Intepreting pairwise WMD flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's sort the distances of the words that created the most distance from the positive to the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'film': 4.534129999999999,\n",
       " 'movie': 3.938469999999998,\n",
       " 'story': 3.434129999999999,\n",
       " 'great': 3.077940000000002,\n",
       " 'love': 2.9721399999999996,\n",
       " 'performance': 2.73945,\n",
       " 'life': 2.426700000000001,\n",
       " 'character': 2.39385,\n",
       " 'best': 2.340230000000001,\n",
       " 'well': 2.3356999999999988,\n",
       " 'watch': 2.2191299999999994,\n",
       " 'show': 2.1959499999999994,\n",
       " 'still': 2.195579999999999,\n",
       " 'scene': 2.19522,\n",
       " 'good': 2.1382,\n",
       " 'time': 2.09075,\n",
       " 'comedy': 2.08384,\n",
       " 'young': 2.0808300000000015,\n",
       " 'one': 2.0784700000000003,\n",
       " 'like': 2.015480000000001,\n",
       " 'dvd': 2.01107,\n",
       " 'excellent': 2.0090300000000005,\n",
       " 'people': 1.9920699999999996,\n",
       " 'fan': 1.9595799999999997,\n",
       " 'actor': 1.87092,\n",
       " 'role': 1.86876,\n",
       " 'see': 1.8347,\n",
       " 'little': 1.8331200000000005,\n",
       " 'loved': 1.83208,\n",
       " 'family': 1.7825199999999999}"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.wc_X1.items(), key=lambda item: item[1], reverse=True)[:30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see what added most distance when moving from the negative to the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 6.2731,\n",
       " 'bad': 5.4052500000000006,\n",
       " 'film': 4.1417399999999995,\n",
       " 'worst': 3.635940000000001,\n",
       " 'plot': 3.55549,\n",
       " 'waste': 3.1293699999999993,\n",
       " 'scene': 3.013090000000001,\n",
       " 'acting': 2.7281000000000004,\n",
       " 'character': 2.5816599999999994,\n",
       " 'made': 2.4689400000000004,\n",
       " 'rating': 2.45743,\n",
       " 'like': 2.45132,\n",
       " 'ever': 2.3756300000000006,\n",
       " 'stupid': 2.34381,\n",
       " 'actor': 2.2481300000000006,\n",
       " 'story': 2.22648,\n",
       " 'funny': 2.2264,\n",
       " 'really': 2.2117,\n",
       " 'boring': 2.2083199999999996,\n",
       " 'watch': 2.19631,\n",
       " 'good': 2.1373299999999995,\n",
       " 'even': 2.0962,\n",
       " 'thing': 2.0919399999999997,\n",
       " 'money': 2.0855600000000005,\n",
       " 'watching': 2.039080000000001,\n",
       " 'guy': 1.9936299999999998,\n",
       " 'awful': 1.9861900000000003,\n",
       " 'would': 1.9547700000000006,\n",
       " 'seen': 1.9501299999999995,\n",
       " 'see': 1.93109}"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.wc_X2.items(), key=lambda item: item[1], reverse=True)[:30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the distances between the two sets by clustering similar words, in order to get a better sense of what kind of \"topics\" that separate them. Each cluster has a weight that matches the sum of the words belonging to that cluster. We choose *n* top clusters to inspect. To make the clusters interpretable, we also represent each of them by *m* keywords, selected based on the cost they individually add between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50\n",
    "n_words = 10\n",
    "\n",
    "c1 = output_clusters(wc=wmd_pairs_flow.wc_X1.items(), \n",
    "                     cc=wmd_pairs_flow.cc_X1.items(), \n",
    "                     c2w=cluster2words, \n",
    "                     n_clusters=n_clusters, \n",
    "                     n_words=n_words)\n",
    "c2 = output_clusters(wc=wmd_pairs_flow.wc_X2.items(), \n",
    "                     cc=wmd_pairs_flow.cc_X2.items(), \n",
    "                     c2w=cluster2words, \n",
    "                     n_clusters=n_clusters, \n",
    "                     n_words=n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive to negative clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>36</th>\n",
       "      <th>62</th>\n",
       "      <th>48</th>\n",
       "      <th>81</th>\n",
       "      <th>10</th>\n",
       "      <th>27</th>\n",
       "      <th>52</th>\n",
       "      <th>58</th>\n",
       "      <th>75</th>\n",
       "      <th>25</th>\n",
       "      <th>...</th>\n",
       "      <th>78</th>\n",
       "      <th>65</th>\n",
       "      <th>11</th>\n",
       "      <th>9</th>\n",
       "      <th>61</th>\n",
       "      <th>63</th>\n",
       "      <th>39</th>\n",
       "      <th>32</th>\n",
       "      <th>49</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well (2.34)</td>\n",
       "      <td>performance (2.74)</td>\n",
       "      <td>effect (1.15)</td>\n",
       "      <td>john (1.06)</td>\n",
       "      <td>make (1.57)</td>\n",
       "      <td>great (3.08)</td>\n",
       "      <td>u (1.35)</td>\n",
       "      <td>role (1.87)</td>\n",
       "      <td>man (1.67)</td>\n",
       "      <td>dvd (2.01)</td>\n",
       "      <td>...</td>\n",
       "      <td>fan (1.96)</td>\n",
       "      <td>mickey (0.68)</td>\n",
       "      <td>house (0.85)</td>\n",
       "      <td>black (1.0)</td>\n",
       "      <td>art (1.16)</td>\n",
       "      <td>evil (0.93)</td>\n",
       "      <td>heart (0.94)</td>\n",
       "      <td>romantic (1.19)</td>\n",
       "      <td>taste (0.54)</td>\n",
       "      <td>question (0.87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>still (2.2)</td>\n",
       "      <td>show (2.2)</td>\n",
       "      <td>human (1.03)</td>\n",
       "      <td>robert (0.91)</td>\n",
       "      <td>get (1.57)</td>\n",
       "      <td>excellent (2.01)</td>\n",
       "      <td>oscar (0.78)</td>\n",
       "      <td>work (1.72)</td>\n",
       "      <td>old (1.65)</td>\n",
       "      <td>tv (1.47)</td>\n",
       "      <td>...</td>\n",
       "      <td>actor (1.87)</td>\n",
       "      <td>guy (0.62)</td>\n",
       "      <td>seat (0.81)</td>\n",
       "      <td>white (0.75)</td>\n",
       "      <td>school (0.88)</td>\n",
       "      <td>mystery (0.76)</td>\n",
       "      <td>brain (0.67)</td>\n",
       "      <td>seductive (0.42)</td>\n",
       "      <td>meatball (0.48)</td>\n",
       "      <td>problem (0.66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like (2.02)</td>\n",
       "      <td>time (2.09)</td>\n",
       "      <td>high (0.86)</td>\n",
       "      <td>mary (0.89)</td>\n",
       "      <td>take (1.54)</td>\n",
       "      <td>wonderful (1.65)</td>\n",
       "      <td>cant (0.51)</td>\n",
       "      <td>part (1.38)</td>\n",
       "      <td>friend (1.31)</td>\n",
       "      <td>italian (1.32)</td>\n",
       "      <td>...</td>\n",
       "      <td>hero (0.87)</td>\n",
       "      <td>hell (0.56)</td>\n",
       "      <td>room (0.55)</td>\n",
       "      <td>brown (0.67)</td>\n",
       "      <td>lesson (0.58)</td>\n",
       "      <td>ghost (0.44)</td>\n",
       "      <td>memory (0.67)</td>\n",
       "      <td>artistic (0.4)</td>\n",
       "      <td>popcorn (0.32)</td>\n",
       "      <td>situation (0.66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people (1.99)</td>\n",
       "      <td>one (2.08)</td>\n",
       "      <td>number (0.84)</td>\n",
       "      <td>joe (0.84)</td>\n",
       "      <td>find (1.36)</td>\n",
       "      <td>entertaining (1.41)</td>\n",
       "      <td>batman (0.41)</td>\n",
       "      <td>relationship (0.98)</td>\n",
       "      <td>girl (1.22)</td>\n",
       "      <td>disney (1.19)</td>\n",
       "      <td>...</td>\n",
       "      <td>writer (0.68)</td>\n",
       "      <td>stuff (0.54)</td>\n",
       "      <td>street (0.51)</td>\n",
       "      <td>accent (0.59)</td>\n",
       "      <td>student (0.45)</td>\n",
       "      <td>universe (0.4)</td>\n",
       "      <td>gene (0.61)</td>\n",
       "      <td>imagery (0.36)</td>\n",
       "      <td>ham (0.3)</td>\n",
       "      <td>reason (0.56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little (1.83)</td>\n",
       "      <td>year (1.57)</td>\n",
       "      <td>small (0.82)</td>\n",
       "      <td>tom (0.81)</td>\n",
       "      <td>go (1.35)</td>\n",
       "      <td>perfect (1.36)</td>\n",
       "      <td>betty (0.41)</td>\n",
       "      <td>theme (0.95)</td>\n",
       "      <td>actress (1.1)</td>\n",
       "      <td>american (1.18)</td>\n",
       "      <td>...</td>\n",
       "      <td>artist (0.44)</td>\n",
       "      <td>yes (0.5)</td>\n",
       "      <td>glass (0.5)</td>\n",
       "      <td>costume (0.52)</td>\n",
       "      <td>chemistry (0.44)</td>\n",
       "      <td>zodiac (0.36)</td>\n",
       "      <td>hospital (0.55)</td>\n",
       "      <td>subtle (0.33)</td>\n",
       "      <td>eat (0.26)</td>\n",
       "      <td>flaw (0.52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>real (1.76)</td>\n",
       "      <td>cast (1.51)</td>\n",
       "      <td>usual (0.77)</td>\n",
       "      <td>james (0.77)</td>\n",
       "      <td>keep (1.3)</td>\n",
       "      <td>brilliant (1.27)</td>\n",
       "      <td>fx (0.41)</td>\n",
       "      <td>direction (0.8)</td>\n",
       "      <td>father (1.06)</td>\n",
       "      <td>hollywood (1.09)</td>\n",
       "      <td>...</td>\n",
       "      <td>guest (0.34)</td>\n",
       "      <td>crazy (0.47)</td>\n",
       "      <td>wheelchair (0.5)</td>\n",
       "      <td>jean (0.5)</td>\n",
       "      <td>academy (0.44)</td>\n",
       "      <td>planet (0.35)</td>\n",
       "      <td>disease (0.36)</td>\n",
       "      <td>visually (0.32)</td>\n",
       "      <td>fat (0.26)</td>\n",
       "      <td>issue (0.49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>much (1.72)</td>\n",
       "      <td>first (1.32)</td>\n",
       "      <td>major (0.76)</td>\n",
       "      <td>jim (0.77)</td>\n",
       "      <td>give (1.28)</td>\n",
       "      <td>nice (1.14)</td>\n",
       "      <td>fav (0.41)</td>\n",
       "      <td>experience (0.77)</td>\n",
       "      <td>woman (1.04)</td>\n",
       "      <td>york (0.7)</td>\n",
       "      <td>...</td>\n",
       "      <td>reviewer (0.33)</td>\n",
       "      <td>okay (0.39)</td>\n",
       "      <td>box (0.4)</td>\n",
       "      <td>hair (0.37)</td>\n",
       "      <td>class (0.44)</td>\n",
       "      <td>villain (0.32)</td>\n",
       "      <td>psychological (0.34)</td>\n",
       "      <td>mannerism (0.3)</td>\n",
       "      <td>cream (0.26)</td>\n",
       "      <td>challenge (0.39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>way (1.57)</td>\n",
       "      <td>special (1.22)</td>\n",
       "      <td>across (0.74)</td>\n",
       "      <td>george (0.76)</td>\n",
       "      <td>become (0.94)</td>\n",
       "      <td>amazing (1.08)</td>\n",
       "      <td>reese (0.35)</td>\n",
       "      <td>atmosphere (0.75)</td>\n",
       "      <td>brother (0.99)</td>\n",
       "      <td>australia (0.6)</td>\n",
       "      <td>...</td>\n",
       "      <td>leader (0.3)</td>\n",
       "      <td>momma (0.39)</td>\n",
       "      <td>bar (0.32)</td>\n",
       "      <td>makeup (0.34)</td>\n",
       "      <td>photography (0.4)</td>\n",
       "      <td>witch (0.31)</td>\n",
       "      <td>facial (0.27)</td>\n",
       "      <td>visual (0.29)</td>\n",
       "      <td>oz (0.25)</td>\n",
       "      <td>lack (0.35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>many (1.54)</td>\n",
       "      <td>day (1.18)</td>\n",
       "      <td>typical (0.7)</td>\n",
       "      <td>jones (0.75)</td>\n",
       "      <td>turn (0.88)</td>\n",
       "      <td>interesting (1.0)</td>\n",
       "      <td>pb (0.33)</td>\n",
       "      <td>depth (0.7)</td>\n",
       "      <td>kid (0.99)</td>\n",
       "      <td>america (0.58)</td>\n",
       "      <td>...</td>\n",
       "      <td>critic (0.29)</td>\n",
       "      <td>hey (0.32)</td>\n",
       "      <td>apartment (0.31)</td>\n",
       "      <td>blue (0.34)</td>\n",
       "      <td>computer (0.35)</td>\n",
       "      <td>creepy (0.3)</td>\n",
       "      <td>blood (0.25)</td>\n",
       "      <td>wistful (0.29)</td>\n",
       "      <td>eating (0.25)</td>\n",
       "      <td>difficulty (0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>really (1.5)</td>\n",
       "      <td>short (1.15)</td>\n",
       "      <td>rating (0.69)</td>\n",
       "      <td>mr (0.74)</td>\n",
       "      <td>meet (0.87)</td>\n",
       "      <td>awesome (0.94)</td>\n",
       "      <td>victoria (0.32)</td>\n",
       "      <td>future (0.66)</td>\n",
       "      <td>mother (0.89)</td>\n",
       "      <td>japan (0.58)</td>\n",
       "      <td>...</td>\n",
       "      <td>performer (0.24)</td>\n",
       "      <td>oh (0.29)</td>\n",
       "      <td>hall (0.26)</td>\n",
       "      <td>color (0.24)</td>\n",
       "      <td>college (0.34)</td>\n",
       "      <td>pirate (0.29)</td>\n",
       "      <td>ill (0.24)</td>\n",
       "      <td>symbolism (0.23)</td>\n",
       "      <td>tucker (0.21)</td>\n",
       "      <td>difference (0.29)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              36                  62             48             81  \\\n",
       "0    well (2.34)  performance (2.74)  effect (1.15)    john (1.06)   \n",
       "1    still (2.2)          show (2.2)   human (1.03)  robert (0.91)   \n",
       "2    like (2.02)         time (2.09)    high (0.86)    mary (0.89)   \n",
       "3  people (1.99)          one (2.08)  number (0.84)     joe (0.84)   \n",
       "4  little (1.83)         year (1.57)   small (0.82)     tom (0.81)   \n",
       "5    real (1.76)         cast (1.51)   usual (0.77)   james (0.77)   \n",
       "6    much (1.72)        first (1.32)   major (0.76)     jim (0.77)   \n",
       "7     way (1.57)      special (1.22)  across (0.74)  george (0.76)   \n",
       "8    many (1.54)          day (1.18)  typical (0.7)   jones (0.75)   \n",
       "9   really (1.5)        short (1.15)  rating (0.69)      mr (0.74)   \n",
       "\n",
       "              10                   27               52                   58  \\\n",
       "0    make (1.57)         great (3.08)         u (1.35)          role (1.87)   \n",
       "1     get (1.57)     excellent (2.01)     oscar (0.78)          work (1.72)   \n",
       "2    take (1.54)     wonderful (1.65)      cant (0.51)          part (1.38)   \n",
       "3    find (1.36)  entertaining (1.41)    batman (0.41)  relationship (0.98)   \n",
       "4      go (1.35)       perfect (1.36)     betty (0.41)         theme (0.95)   \n",
       "5     keep (1.3)     brilliant (1.27)        fx (0.41)      direction (0.8)   \n",
       "6    give (1.28)          nice (1.14)       fav (0.41)    experience (0.77)   \n",
       "7  become (0.94)       amazing (1.08)     reese (0.35)    atmosphere (0.75)   \n",
       "8    turn (0.88)    interesting (1.0)        pb (0.33)          depth (0.7)   \n",
       "9    meet (0.87)       awesome (0.94)  victoria (0.32)        future (0.66)   \n",
       "\n",
       "               75                25  ...                78             65  \\\n",
       "0      man (1.67)        dvd (2.01)  ...        fan (1.96)  mickey (0.68)   \n",
       "1      old (1.65)         tv (1.47)  ...      actor (1.87)     guy (0.62)   \n",
       "2   friend (1.31)    italian (1.32)  ...       hero (0.87)    hell (0.56)   \n",
       "3     girl (1.22)     disney (1.19)  ...     writer (0.68)   stuff (0.54)   \n",
       "4   actress (1.1)   american (1.18)  ...     artist (0.44)      yes (0.5)   \n",
       "5   father (1.06)  hollywood (1.09)  ...      guest (0.34)   crazy (0.47)   \n",
       "6    woman (1.04)        york (0.7)  ...   reviewer (0.33)    okay (0.39)   \n",
       "7  brother (0.99)   australia (0.6)  ...      leader (0.3)   momma (0.39)   \n",
       "8      kid (0.99)    america (0.58)  ...     critic (0.29)     hey (0.32)   \n",
       "9   mother (0.89)      japan (0.58)  ...  performer (0.24)      oh (0.29)   \n",
       "\n",
       "                 11              9                  61              63  \\\n",
       "0      house (0.85)     black (1.0)         art (1.16)     evil (0.93)   \n",
       "1       seat (0.81)    white (0.75)      school (0.88)  mystery (0.76)   \n",
       "2       room (0.55)    brown (0.67)      lesson (0.58)    ghost (0.44)   \n",
       "3     street (0.51)   accent (0.59)     student (0.45)  universe (0.4)   \n",
       "4       glass (0.5)  costume (0.52)   chemistry (0.44)   zodiac (0.36)   \n",
       "5  wheelchair (0.5)      jean (0.5)     academy (0.44)   planet (0.35)   \n",
       "6         box (0.4)     hair (0.37)       class (0.44)  villain (0.32)   \n",
       "7        bar (0.32)   makeup (0.34)  photography (0.4)    witch (0.31)   \n",
       "8  apartment (0.31)     blue (0.34)    computer (0.35)    creepy (0.3)   \n",
       "9       hall (0.26)    color (0.24)     college (0.34)   pirate (0.29)   \n",
       "\n",
       "                     39                32               49                 43  \n",
       "0          heart (0.94)   romantic (1.19)     taste (0.54)    question (0.87)  \n",
       "1          brain (0.67)  seductive (0.42)  meatball (0.48)     problem (0.66)  \n",
       "2         memory (0.67)    artistic (0.4)   popcorn (0.32)   situation (0.66)  \n",
       "3           gene (0.61)    imagery (0.36)        ham (0.3)      reason (0.56)  \n",
       "4       hospital (0.55)     subtle (0.33)       eat (0.26)        flaw (0.52)  \n",
       "5        disease (0.36)   visually (0.32)       fat (0.26)       issue (0.49)  \n",
       "6  psychological (0.34)   mannerism (0.3)     cream (0.26)   challenge (0.39)  \n",
       "7         facial (0.27)     visual (0.29)        oz (0.25)        lack (0.35)  \n",
       "8          blood (0.25)    wistful (0.29)    eating (0.25)   difficulty (0.3)  \n",
       "9            ill (0.24)  symbolism (0.23)    tucker (0.21)  difference (0.29)  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative to positive clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>36</th>\n",
       "      <th>62</th>\n",
       "      <th>48</th>\n",
       "      <th>23</th>\n",
       "      <th>10</th>\n",
       "      <th>34</th>\n",
       "      <th>41</th>\n",
       "      <th>86</th>\n",
       "      <th>26</th>\n",
       "      <th>58</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>30</th>\n",
       "      <th>43</th>\n",
       "      <th>64</th>\n",
       "      <th>3</th>\n",
       "      <th>8</th>\n",
       "      <th>78</th>\n",
       "      <th>76</th>\n",
       "      <th>6</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like (2.45)</td>\n",
       "      <td>one (1.93)</td>\n",
       "      <td>rating (2.46)</td>\n",
       "      <td>watch (2.2)</td>\n",
       "      <td>get (1.88)</td>\n",
       "      <td>would (1.95)</td>\n",
       "      <td>movie (6.27)</td>\n",
       "      <td>got (1.58)</td>\n",
       "      <td>action (1.78)</td>\n",
       "      <td>idea (1.34)</td>\n",
       "      <td>...</td>\n",
       "      <td>pretty (1.61)</td>\n",
       "      <td>bored (1.11)</td>\n",
       "      <td>lack (1.29)</td>\n",
       "      <td>sense (1.32)</td>\n",
       "      <td>life (1.39)</td>\n",
       "      <td>name (1.28)</td>\n",
       "      <td>actor (2.25)</td>\n",
       "      <td>animal (0.88)</td>\n",
       "      <td>poorly (1.12)</td>\n",
       "      <td>worse (1.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ever (2.38)</td>\n",
       "      <td>show (1.92)</td>\n",
       "      <td>effect (1.3)</td>\n",
       "      <td>see (1.93)</td>\n",
       "      <td>make (1.87)</td>\n",
       "      <td>could (1.78)</td>\n",
       "      <td>film (4.14)</td>\n",
       "      <td>saw (1.09)</td>\n",
       "      <td>comment (1.32)</td>\n",
       "      <td>work (1.24)</td>\n",
       "      <td>...</td>\n",
       "      <td>totally (1.06)</td>\n",
       "      <td>sorry (0.87)</td>\n",
       "      <td>problem (1.21)</td>\n",
       "      <td>talent (1.14)</td>\n",
       "      <td>child (1.23)</td>\n",
       "      <td>star (1.07)</td>\n",
       "      <td>fan (1.25)</td>\n",
       "      <td>creature (0.79)</td>\n",
       "      <td>badly (0.75)</td>\n",
       "      <td>slow (0.87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>really (2.21)</td>\n",
       "      <td>time (1.74)</td>\n",
       "      <td>main (0.87)</td>\n",
       "      <td>say (1.86)</td>\n",
       "      <td>go (1.76)</td>\n",
       "      <td>try (1.28)</td>\n",
       "      <td>scene (3.01)</td>\n",
       "      <td>seemed (1.06)</td>\n",
       "      <td>case (1.29)</td>\n",
       "      <td>part (1.09)</td>\n",
       "      <td>...</td>\n",
       "      <td>completely (0.95)</td>\n",
       "      <td>tired (0.79)</td>\n",
       "      <td>reason (1.17)</td>\n",
       "      <td>charm (0.72)</td>\n",
       "      <td>care (0.9)</td>\n",
       "      <td>world (0.8)</td>\n",
       "      <td>writer (0.98)</td>\n",
       "      <td>fox (0.65)</td>\n",
       "      <td>relentlessly (0.69)</td>\n",
       "      <td>serious (0.77)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even (2.1)</td>\n",
       "      <td>cast (1.62)</td>\n",
       "      <td>low (0.86)</td>\n",
       "      <td>look (1.64)</td>\n",
       "      <td>find (1.36)</td>\n",
       "      <td>want (1.26)</td>\n",
       "      <td>viewer (1.15)</td>\n",
       "      <td>played (0.96)</td>\n",
       "      <td>review (1.21)</td>\n",
       "      <td>direction (0.9)</td>\n",
       "      <td>...</td>\n",
       "      <td>quite (0.82)</td>\n",
       "      <td>confused (0.62)</td>\n",
       "      <td>mess (0.73)</td>\n",
       "      <td>imagination (0.43)</td>\n",
       "      <td>family (0.79)</td>\n",
       "      <td>blockbuster (0.58)</td>\n",
       "      <td>producer (0.79)</td>\n",
       "      <td>chick (0.56)</td>\n",
       "      <td>quickly (0.61)</td>\n",
       "      <td>hot (0.66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thing (2.09)</td>\n",
       "      <td>first (1.59)</td>\n",
       "      <td>overall (0.84)</td>\n",
       "      <td>recommend (1.15)</td>\n",
       "      <td>save (1.17)</td>\n",
       "      <td>enough (1.26)</td>\n",
       "      <td>gore (1.1)</td>\n",
       "      <td>gave (0.95)</td>\n",
       "      <td>dialogue (1.16)</td>\n",
       "      <td>premise (0.88)</td>\n",
       "      <td>...</td>\n",
       "      <td>truly (0.82)</td>\n",
       "      <td>hated (0.6)</td>\n",
       "      <td>disappointment (0.56)</td>\n",
       "      <td>emotion (0.29)</td>\n",
       "      <td>live (0.49)</td>\n",
       "      <td>dream (0.42)</td>\n",
       "      <td>hero (0.72)</td>\n",
       "      <td>rat (0.46)</td>\n",
       "      <td>often (0.35)</td>\n",
       "      <td>tedious (0.58)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much (1.77)</td>\n",
       "      <td>end (1.57)</td>\n",
       "      <td>standard (0.66)</td>\n",
       "      <td>know (1.14)</td>\n",
       "      <td>give (1.12)</td>\n",
       "      <td>must (1.16)</td>\n",
       "      <td>flick (1.06)</td>\n",
       "      <td>went (0.93)</td>\n",
       "      <td>budget (0.99)</td>\n",
       "      <td>role (0.84)</td>\n",
       "      <td>...</td>\n",
       "      <td>especially (0.46)</td>\n",
       "      <td>sick (0.57)</td>\n",
       "      <td>situation (0.49)</td>\n",
       "      <td>oddness (0.27)</td>\n",
       "      <td>kibbutz (0.45)</td>\n",
       "      <td>hype (0.36)</td>\n",
       "      <td>critic (0.56)</td>\n",
       "      <td>spider (0.4)</td>\n",
       "      <td>self (0.28)</td>\n",
       "      <td>confusing (0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>people (1.74)</td>\n",
       "      <td>least (1.5)</td>\n",
       "      <td>single (0.66)</td>\n",
       "      <td>mean (1.05)</td>\n",
       "      <td>take (0.97)</td>\n",
       "      <td>please (1.11)</td>\n",
       "      <td>screen (0.91)</td>\n",
       "      <td>watched (0.92)</td>\n",
       "      <td>opinion (0.69)</td>\n",
       "      <td>example (0.71)</td>\n",
       "      <td>...</td>\n",
       "      <td>extremely (0.46)</td>\n",
       "      <td>spoiled (0.43)</td>\n",
       "      <td>trouble (0.46)</td>\n",
       "      <td>sheer (0.27)</td>\n",
       "      <td>native (0.37)</td>\n",
       "      <td>former (0.36)</td>\n",
       "      <td>godfather (0.39)</td>\n",
       "      <td>hunter (0.38)</td>\n",
       "      <td>ambiguously (0.23)</td>\n",
       "      <td>impossible (0.45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nothing (1.62)</td>\n",
       "      <td>hour (1.48)</td>\n",
       "      <td>along (0.64)</td>\n",
       "      <td>understand (1.0)</td>\n",
       "      <td>turn (0.91)</td>\n",
       "      <td>trying (1.06)</td>\n",
       "      <td>imdb (0.86)</td>\n",
       "      <td>left (0.86)</td>\n",
       "      <td>group (0.67)</td>\n",
       "      <td>effort (0.65)</td>\n",
       "      <td>...</td>\n",
       "      <td>highly (0.38)</td>\n",
       "      <td>angry (0.42)</td>\n",
       "      <td>difference (0.42)</td>\n",
       "      <td>spirit (0.27)</td>\n",
       "      <td>country (0.36)</td>\n",
       "      <td>attention (0.34)</td>\n",
       "      <td>reviewer (0.37)</td>\n",
       "      <td>joey (0.37)</td>\n",
       "      <td>briefly (0.22)</td>\n",
       "      <td>extreme (0.39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>think (1.59)</td>\n",
       "      <td>back (1.3)</td>\n",
       "      <td>light (0.62)</td>\n",
       "      <td>sit (0.99)</td>\n",
       "      <td>keep (0.78)</td>\n",
       "      <td>need (1.02)</td>\n",
       "      <td>sequel (0.81)</td>\n",
       "      <td>lost (0.84)</td>\n",
       "      <td>act (0.66)</td>\n",
       "      <td>view (0.61)</td>\n",
       "      <td>...</td>\n",
       "      <td>generally (0.33)</td>\n",
       "      <td>scared (0.41)</td>\n",
       "      <td>question (0.39)</td>\n",
       "      <td>ego (0.23)</td>\n",
       "      <td>living (0.31)</td>\n",
       "      <td>favorite (0.32)</td>\n",
       "      <td>creator (0.36)</td>\n",
       "      <td>whale (0.37)</td>\n",
       "      <td>loosely (0.22)</td>\n",
       "      <td>nasty (0.37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lot (1.51)</td>\n",
       "      <td>series (1.22)</td>\n",
       "      <td>human (0.6)</td>\n",
       "      <td>tell (0.96)</td>\n",
       "      <td>use (0.76)</td>\n",
       "      <td>looking (0.98)</td>\n",
       "      <td>cinematography (0.6)</td>\n",
       "      <td>came (0.81)</td>\n",
       "      <td>call (0.57)</td>\n",
       "      <td>belief (0.47)</td>\n",
       "      <td>...</td>\n",
       "      <td>somewhat (0.32)</td>\n",
       "      <td>wondering (0.39)</td>\n",
       "      <td>mistake (0.36)</td>\n",
       "      <td>brevity (0.23)</td>\n",
       "      <td>justice (0.27)</td>\n",
       "      <td>history (0.32)</td>\n",
       "      <td>carver (0.23)</td>\n",
       "      <td>reptile (0.33)</td>\n",
       "      <td>randomly (0.21)</td>\n",
       "      <td>tough (0.36)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               36             62               48                23  \\\n",
       "0     like (2.45)     one (1.93)    rating (2.46)       watch (2.2)   \n",
       "1     ever (2.38)    show (1.92)     effect (1.3)        see (1.93)   \n",
       "2   really (2.21)    time (1.74)      main (0.87)        say (1.86)   \n",
       "3      even (2.1)    cast (1.62)       low (0.86)       look (1.64)   \n",
       "4    thing (2.09)   first (1.59)   overall (0.84)  recommend (1.15)   \n",
       "5     much (1.77)     end (1.57)  standard (0.66)       know (1.14)   \n",
       "6   people (1.74)    least (1.5)    single (0.66)       mean (1.05)   \n",
       "7  nothing (1.62)    hour (1.48)     along (0.64)  understand (1.0)   \n",
       "8    think (1.59)     back (1.3)     light (0.62)        sit (0.99)   \n",
       "9      lot (1.51)  series (1.22)      human (0.6)       tell (0.96)   \n",
       "\n",
       "            10              34                    41              86  \\\n",
       "0   get (1.88)    would (1.95)          movie (6.27)      got (1.58)   \n",
       "1  make (1.87)    could (1.78)           film (4.14)      saw (1.09)   \n",
       "2    go (1.76)      try (1.28)          scene (3.01)   seemed (1.06)   \n",
       "3  find (1.36)     want (1.26)         viewer (1.15)   played (0.96)   \n",
       "4  save (1.17)   enough (1.26)            gore (1.1)     gave (0.95)   \n",
       "5  give (1.12)     must (1.16)          flick (1.06)     went (0.93)   \n",
       "6  take (0.97)   please (1.11)         screen (0.91)  watched (0.92)   \n",
       "7  turn (0.91)   trying (1.06)           imdb (0.86)     left (0.86)   \n",
       "8  keep (0.78)     need (1.02)         sequel (0.81)     lost (0.84)   \n",
       "9   use (0.76)  looking (0.98)  cinematography (0.6)     came (0.81)   \n",
       "\n",
       "                26               58  ...                 98                30  \\\n",
       "0    action (1.78)      idea (1.34)  ...      pretty (1.61)      bored (1.11)   \n",
       "1   comment (1.32)      work (1.24)  ...     totally (1.06)      sorry (0.87)   \n",
       "2      case (1.29)      part (1.09)  ...  completely (0.95)      tired (0.79)   \n",
       "3    review (1.21)  direction (0.9)  ...       quite (0.82)   confused (0.62)   \n",
       "4  dialogue (1.16)   premise (0.88)  ...       truly (0.82)       hated (0.6)   \n",
       "5    budget (0.99)      role (0.84)  ...  especially (0.46)       sick (0.57)   \n",
       "6   opinion (0.69)   example (0.71)  ...   extremely (0.46)    spoiled (0.43)   \n",
       "7     group (0.67)    effort (0.65)  ...      highly (0.38)      angry (0.42)   \n",
       "8       act (0.66)      view (0.61)  ...   generally (0.33)     scared (0.41)   \n",
       "9      call (0.57)    belief (0.47)  ...    somewhat (0.32)  wondering (0.39)   \n",
       "\n",
       "                      43                  64              3   \\\n",
       "0            lack (1.29)        sense (1.32)     life (1.39)   \n",
       "1         problem (1.21)       talent (1.14)    child (1.23)   \n",
       "2          reason (1.17)        charm (0.72)      care (0.9)   \n",
       "3            mess (0.73)  imagination (0.43)   family (0.79)   \n",
       "4  disappointment (0.56)      emotion (0.29)     live (0.49)   \n",
       "5       situation (0.49)      oddness (0.27)  kibbutz (0.45)   \n",
       "6         trouble (0.46)        sheer (0.27)   native (0.37)   \n",
       "7      difference (0.42)       spirit (0.27)  country (0.36)   \n",
       "8        question (0.39)          ego (0.23)   living (0.31)   \n",
       "9         mistake (0.36)      brevity (0.23)  justice (0.27)   \n",
       "\n",
       "                   8                 78               76                   6   \\\n",
       "0         name (1.28)      actor (2.25)    animal (0.88)        poorly (1.12)   \n",
       "1         star (1.07)        fan (1.25)  creature (0.79)         badly (0.75)   \n",
       "2         world (0.8)     writer (0.98)       fox (0.65)  relentlessly (0.69)   \n",
       "3  blockbuster (0.58)   producer (0.79)     chick (0.56)       quickly (0.61)   \n",
       "4        dream (0.42)       hero (0.72)       rat (0.46)         often (0.35)   \n",
       "5         hype (0.36)     critic (0.56)     spider (0.4)          self (0.28)   \n",
       "6       former (0.36)  godfather (0.39)    hunter (0.38)   ambiguously (0.23)   \n",
       "7    attention (0.34)   reviewer (0.37)      joey (0.37)       briefly (0.22)   \n",
       "8     favorite (0.32)    creator (0.36)     whale (0.37)       loosely (0.22)   \n",
       "9      history (0.32)     carver (0.23)   reptile (0.33)      randomly (0.21)   \n",
       "\n",
       "                  13  \n",
       "0       worse (1.22)  \n",
       "1        slow (0.87)  \n",
       "2     serious (0.77)  \n",
       "3         hot (0.66)  \n",
       "4     tedious (0.58)  \n",
       "5    confusing (0.5)  \n",
       "6  impossible (0.45)  \n",
       "7     extreme (0.39)  \n",
       "8       nasty (0.37)  \n",
       "9       tough (0.36)  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Many-to-many WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a first attempt to do the flows from words between many documents, without first filtering using Gale-Shapeley. However, this proved too inefficient. As you can see looking at the CPU times, it is very slow even with extremely small samples and the time complexity is quadratic (or worse?), meaning it rapidly gets even worse as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 12.7 s, total: 2min 1s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%time m2m_distances = WMDManyToMany(pos_docs[:20], neg_docs[:20],E,idx2word).get_distances(return_flow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 13.5 s, total: 2min 5s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%time m2m_distances_flow, wc_X1, wc_X2 = WMDManyToMany(pos_docs[:20],neg_docs[:20],E,idx2word).get_distances(return_flow = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'karen': 8.69223,\n",
       " 'wrenching': 8.31882,\n",
       " 'carpenter': 7.468960000000001,\n",
       " 'laughter': 7.467879999999999,\n",
       " 'liked': 6.864090000000003,\n",
       " 'mom': 6.791519999999999,\n",
       " 'gut': 6.759419999999999,\n",
       " 'love': 6.551409999999997,\n",
       " 'camp': 6.533080000000001,\n",
       " 'hr': 6.1393699999999995}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wc_X1.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hopper': 8.372459999999998,\n",
       " 'jake': 7.63837,\n",
       " 'movie': 7.267059999999995,\n",
       " 'film': 6.936379999999998,\n",
       " 'shakespeare': 5.99276,\n",
       " 'oddness': 5.53033,\n",
       " 'terrible': 4.943440000000001,\n",
       " 'parent': 4.751790000000001,\n",
       " 'actor': 4.672620000000001,\n",
       " 'bad': 4.430020000000002}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wc_X2.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-fwmd",
   "language": "python",
   "name": "venv-fwmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
