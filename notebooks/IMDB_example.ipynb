{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from flow_wmd.documents import Document\n",
    "from flow_wmd.gale_shapeley import Matcher\n",
    "from flow_wmd.models import LC_RWMD, WMD, WMDManyToMany, WMDPairs\n",
    "from flow_wmd.utils import *\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import cluster\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare IMDB data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data and stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\"\n",
    "imdb_data = pd.read_csv(f\"{PATH}IMDB_Dataset.csv\")\n",
    "stopword_list=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Remove special formatting and stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords before denoising, lemmatizing and removing special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 s, sys: 223 ms, total: 35.7 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tokenizer=ToktokTokenizer()\n",
    "imdb_data['review_clean']= [remove_stopwords(r, stopword_list, tokenizer) for r in imdb_data['review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise, remove special characters, lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 192 ms, total: 25 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(denoise_text)\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(remove_special_characters)\n",
    "imdb_data['review_clean']=imdb_data['review_clean'].apply(simple_lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords again, after other preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 67.1 ms, total: 19.8 s\n",
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "imdb_data['review_clean']= [remove_stopwords(r, stopword_list, tokenizer) for r in imdb_data['review_clean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data _before_ preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data _after_ preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data['review_clean'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Separate pos and neg reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = imdb_data[imdb_data.sentiment == \"positive\"].reset_index(drop=True)\n",
    "neg = imdb_data[imdb_data.sentiment == \"negative\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos.review_clean.tolist()\n",
    "neg = neg.review_clean.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize and \"sample\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tok = list(map(lambda x: tokenize(x, tokenizer), pos[:500]))\n",
    "neg_tok = list(map(lambda x: tokenize(x, tokenizer), neg[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sample = [\" \".join(doc) for doc in pos_tok]\n",
    "neg_sample = [\" \".join(doc) for doc in neg_tok]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load pretrained Google News W2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GoogleNews Vectors finetuned using IMDB review data.\n",
      "CPU times: user 18.9 s, sys: 273 ms, total: 19.2 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "if not finetuned:\n",
    "    print(\"Loading GoogleNews Vectors\")\n",
    "    %time model = KeyedVectors.load_word2vec_format('../embeddings/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "else:\n",
    "    print(\"Loading GoogleNews Vectors finetuned using IMDB review data.\")\n",
    "    %time model = KeyedVectors.load_word2vec_format('../embeddings/imdb_w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load corpus and remove OOV words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 µs, sys: 0 ns, total: 19 µs\n",
      "Wall time: 21 µs\n",
      "CPU times: user 241 ms, sys: 5.27 ms, total: 246 ms\n",
      "Wall time: 247 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(norm='l1',\n",
       "                tokenizer=<function tfidf_tokenize at 0x7ff61fd320d0>,\n",
       "                use_idf=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pos_sample + neg_sample\n",
    "\n",
    "%time vectorizer = TfidfVectorizer(use_idf=False, tokenizer=tfidf_tokenize, norm='l1')\n",
    "%time vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 439 µs, total: 12.5 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time oov = [word for word in vectorizer.get_feature_names() if word not in model.key_to_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.5 s, sys: 6.75 ms, total: 1.51 s\n",
      "Wall time: 1.52 s\n",
      "CPU times: user 1.4 s, sys: 5.97 ms, total: 1.4 s\n",
      "Wall time: 1.41 s\n"
     ]
    }
   ],
   "source": [
    "%time pos_sample = list(map(lambda x: remove_oov(x, tokenizer, oov), pos_sample[:500]))\n",
    "%time neg_sample = list(map(lambda x: remove_oov(x, tokenizer, oov), neg_sample[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 µs, sys: 0 ns, total: 23 µs\n",
      "Wall time: 26 µs\n",
      "CPU times: user 227 ms, sys: 3.78 ms, total: 231 ms\n",
      "Wall time: 230 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(norm='l1',\n",
       "                tokenizer=<function tfidf_tokenize at 0x7ff61fd320d0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pos_sample + neg_sample\n",
    "\n",
    "%time vectorizer = TfidfVectorizer(use_idf=True, tokenizer=tfidf_tokenize,norm='l1')\n",
    "%time vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-words vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 3.81 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "pos_nbow = vectorizer.transform(pos_sample)\n",
    "neg_nbow = vectorizer.transform(neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tok = list(map(lambda x: tokenize(x, tokenizer), pos_sample[:500]))\n",
    "neg_tok =list(map(lambda x: tokenize(x, tokenizer), neg_sample[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'reviewer',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scene',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tok[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 ms, sys: 539 µs, total: 15.2 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time oov_ = [word for word in vectorizer.get_feature_names() if word not in model.key_to_index.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oov_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Get features and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()\n",
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "idx2word = {idx: word for idx, word in enumerate(vectorizer.get_feature_names())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the embedding matrix \"E\" for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.vstack([model.get_vector(word) for word in vectorizer.get_feature_names()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the results of the WMD model more interpretable, we add the option to inspect the output not only by individual words, but also by *word clusters*. We do this by clustering the input words with Kmeans and assigning each word to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get the embeddings for the words that are in our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we select the number of clusters we want, initialize the Kmeans model and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n",
      "45\n",
      "50\n",
      "55\n",
      "60\n",
      "65\n",
      "70\n",
      "75\n",
      "80\n",
      "85\n",
      "90\n",
      "95\n",
      "100\n",
      "CPU times: user 17min 23s, sys: 2min 15s, total: 19min 39s\n",
      "Wall time: 3min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "K = range(5,105, 5)\n",
    "for k in K:\n",
    "    print(k)\n",
    "    km = cluster.KMeans(n_clusters=k)\n",
    "    km = km.fit(X)\n",
    "    sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=100)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLUSTERS = 100\n",
    "kmeans = cluster.KMeans(n_clusters=NUM_CLUSTERS, verbose=0)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign labels and centroids to separate variables for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an index that maps each word to a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2cluster = {features[idx]: cl for idx, cl in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aaargh', 12), ('aaliyah', 45), ('aamir', 28), ('aaron', 79), ('ab', 28), ('abandon', 0), ('abandoned', 77), ('abba', 12), ('abbey', 97), ('abbot', 97)]\n"
     ]
    }
   ],
   "source": [
    "print(take(10, word2cluster.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, conversely, create an index that maps each cluster to a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2words = defaultdict(list)\n",
    "for key, value in word2cluster.items():\n",
    "    cluster2words[value].append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon', 'accepting', 'activity', 'adamant', 'addict', 'admits', 'adoption', 'aggression', 'agreeing', 'aiming', 'alcoholism', 'alert', 'alleged', 'allegiance', 'angered', 'answering', 'application', 'asserts', 'assures', 'authority', 'avoiding', 'basterds', 'behalf', 'betray', 'betraying', 'blaming', 'blindly', 'blocked', 'bravely', 'brink', 'casualty', 'caused', 'cease', 'censor', 'charged', 'cheat', 'chooses', 'choosing', 'circumstance', 'citizen', 'complacent', 'compliance', 'complicate', 'condition', 'confront', 'confronted', 'conscious', 'considers', 'console', 'consume', 'consumed', 'control', 'controlling', 'convenience', 'converted', 'cope', 'counter', 'crisis', 'daily', 'damage', 'damaged', 'damnation', 'dealing', 'dealt', 'deciding', 'declare', 'dedicated', 'defect', 'defend', 'defense', 'denied', 'denying', 'dependency', 'deprived', 'desired', 'desperately', 'destitute', 'deterred', 'discredit', 'disease', 'dormant', 'drastic', 'drug', 'duty', 'earning', 'enable', 'enabling', 'encouraged', 'encouraging', 'enforce', 'equipped', 'error', 'execute', 'executing', 'exhaustion', 'experimentation', 'exposed', 'exposing', 'extract', 'faced']\n"
     ]
    }
   ],
   "source": [
    "print(cluster2words[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Initialize documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all reviews into \"documents\", each with a set of weights per word in the corpus (\"nbow\"), the sum of these weights (\"weights_sum\"), the indeces of the words in the documents (\"idxs\") and the word vectors corresponding to each word (\"vecs\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x14766 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_nbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 221 ms, sys: 63.6 ms, total: 285 ms\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pos_docs, neg_docs = [], []\n",
    "\n",
    "for idx, doc in enumerate(pos_tok):\n",
    "    pos_docs.append(Document(doc, pos_nbow[idx], word2idx, E))\n",
    "    \n",
    "for idx, doc in enumerate(neg_tok):\n",
    "    neg_docs.append(Document(doc, neg_nbow[idx], word2idx, E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].nbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].weights_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9728, 13334, 9238, 10277, 6187, 4652, 6699, 10286, 2094, 6701]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].idxs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03184877,  0.08938561, -0.23239496, -0.22144787,  0.00298812,\n",
       "       -0.16498049, -0.1524208 ,  0.21617717, -0.37542573,  0.06170934],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_docs[0].vecs[:1][0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Linear-Complexity Relaxed WMD (LC-RWMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the [Linear-Complexity Relaxed WMD](https://arxiv.org/abs/1711.07227) to get the distances between all positive and all negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 12 µs, total: 25 µs\n",
      "Wall time: 28.8 µs\n",
      "CPU times: user 2min 22s, sys: 21 s, total: 2min 43s\n",
      "Wall time: 42.8 s\n"
     ]
    }
   ],
   "source": [
    "%time lc_rwmd = LC_RWMD(pos_docs, neg_docs,pos_nbow,neg_nbow,E)\n",
    "%time lc_rwmd.get_D()\n",
    "#%time lc_rwmd.get_L(1)\n",
    "#%time lc_rwmd.get_rwmd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Gale-Shapeley Pairing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [Gale-Shapeley matching algorithm](https://en.wikipedia.org/wiki/Gale%E2%80%93Shapley_algorithm) to find the optimal pairs between positive and negative reviews. This iterates over all the reviews and finds the set of matches that pairs each review with its optimal match given that all positive reviews have to be matched with a negative review and vice versa. The output is a dictionary of key-value pairs, where each pair represents an optimal match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 19.3 ms, total: 1.07 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matcher = Matcher(lc_rwmd.D)\n",
    "engaged = matcher.matchmaker()\n",
    "matcher.check()\n",
    "pairs = engaged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of Gale-Shapeley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(185, 299),\n",
       " (35, 473),\n",
       " (336, 28),\n",
       " (188, 248),\n",
       " (101, 148),\n",
       " (253, 15),\n",
       " (133, 258),\n",
       " (104, 259),\n",
       " (131, 377),\n",
       " (107, 10)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, pairs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pairs = [(' '.join(word for word in pos_docs[p[0]].words), \n",
    "                  ' '.join(word for word in neg_docs[p[1]].words))\n",
    "                 for p in take(10, pairs.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game rank far honor playing mine p graphic really good voice acting standard difficulty level right best character series opinion story amazed took many different twist expecting rating game deserves great'"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pairs[9][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'terrible misfortune view entirety say save time money got worst time even called like fails aspect make good movie story interesting actor believable bad direction action sequence fake almost funny almost movie packed full crappy oneliners respectable person could find amusing least little bit movie supposed geared towards men woman utterly unattractive especially old wrinkled thing come towards end try appear sexy weird horrible costume fail miserably even ridiculous still give laugh painful watch'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pairs[9][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9 Pairwise WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the pairwise distances between the documents selected by the Galey-Shapeley algorithm _without_ returning the flow between individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated distances between 0 documents.\n",
      "Calculated distances between 100 documents.\n",
      "Calculated distances between 200 documents.\n",
      "Calculated distances between 300 documents.\n",
      "Calculated distances between 400 documents.\n",
      "CPU times: user 2min 26s, sys: 13.4 s, total: 2min 39s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "wmd_pairs = WMDPairs(pos_docs,neg_docs,pairs,E,idx2word)\n",
    "wmd_pairs.get_distances(thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value is a matrix of distances between the document pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd_pairs.distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the pairwise distances between the documents selected by the Galey-Shapeley algorithm, this time also returning the flow between individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated distances between approximately 0 documents.\n",
      "Calculated distances between approximately 100 documents.\n",
      "Calculated distances between approximately 200 documents.\n",
      "Calculated distances between approximately 300 documents.\n",
      "Calculated distances between approximately 400 documents.\n",
      "CPU times: user 2min 12s, sys: 13.2 s, total: 2min 25s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "wmd_pairs_flow = WMDPairs(pos_docs,neg_docs,pairs,E,idx2word)\n",
    "wmd_pairs_flow.get_distances(return_flow = True, \n",
    "                             sum_clusters = True, \n",
    "                             w2c = word2cluster, \n",
    "                             c2w = cluster2words,\n",
    "                             thread = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three return values.\n",
    "\n",
    "The first one is again a matrix of distances between the document pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd_pairs_flow.distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second return value is a list of tuples with all the words that contributed the most to the distance from the positive documents to the negative ones. These are _not_ sorted from high to low or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('youtube', 0.09996),\n",
       " ('interest', 0.6890999999999999),\n",
       " ('bumping', 0.02748),\n",
       " ('amateur', 0.07795),\n",
       " ('abbreviated', 0.0189),\n",
       " ('frisky', 0.02511),\n",
       " ('renovated', 0.03214),\n",
       " ('cue', 0.00858),\n",
       " ('drive', 0.31423),\n",
       " ('keaton', 0.1514)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.wc_X1.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third return value is a list of tuples with all the words that contributed the most to the distance from the negative documents to the positive ones. Again, these are _not_ sorted from high to low or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('youtube', 0.00701),\n",
       " ('interest', 1.0196800000000001),\n",
       " ('superstar', 0.029),\n",
       " ('amateur', 0.17423),\n",
       " ('critique', 0.19007000000000002),\n",
       " ('tremaine', 0.022299999999999997),\n",
       " ('skiing', 0.03281),\n",
       " ('shabby', 0.03551),\n",
       " ('effeminate', 0.04624),\n",
       " ('abbreviated', 0.01819)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.wc_X2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 8.81814),\n",
       " (45, 7.456930000000001),\n",
       " (28, 12.431749999999997),\n",
       " (79, 20.24658999999999),\n",
       " (0, 13.81794999999999),\n",
       " (77, 11.385559999999998),\n",
       " (97, 7.7232999999999965),\n",
       " (9, 19.64446),\n",
       " (10, 13.37141),\n",
       " (27, 10.543320000000005)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.cc_X1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 11.17188),\n",
       " (45, 3.565390000000001),\n",
       " (28, 10.005869999999993),\n",
       " (79, 13.041610000000007),\n",
       " (0, 12.748129999999998),\n",
       " (77, 8.873689999999996),\n",
       " (97, 6.21828),\n",
       " (9, 11.726469999999994),\n",
       " (10, 14.408119999999993),\n",
       " (27, 7.2023300000000035)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, wmd_pairs_flow.cc_X2.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24: 94.88465000000011,\n",
       " 1: 54.117840000000044,\n",
       " 21: 49.316789999999976,\n",
       " 4: 47.05581999999993,\n",
       " 73: 39.62008999999993,\n",
       " 65: 38.74738999999996,\n",
       " 55: 37.468270000000025,\n",
       " 19: 34.56766999999994,\n",
       " 69: 33.85297,\n",
       " 39: 33.70846}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.cc_X1.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmd_pairs_flow.get_differences()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Intepreting pairwise WMD flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's sort the distances of the words that created the most distance from the positive to the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'great': 3.684119999999999,\n",
       " 'love': 3.0659199999999993,\n",
       " 'best': 2.9734699999999994,\n",
       " 'young': 2.7412799999999993,\n",
       " 'still': 2.678639999999999,\n",
       " 'performance': 2.4275899999999995,\n",
       " 'excellent': 2.3056899999999994,\n",
       " 'game': 2.0037299999999996,\n",
       " 'loved': 1.9072999999999998,\n",
       " 'favorite': 1.8927700000000005,\n",
       " 'wonderful': 1.8905500000000002,\n",
       " 'well': 1.87352,\n",
       " 'little': 1.7632000000000012,\n",
       " 'dvd': 1.6582800000000009,\n",
       " 'life': 1.63394,\n",
       " 'family': 1.6094199999999994,\n",
       " 'song': 1.47339,\n",
       " 'perfect': 1.42944,\n",
       " 'story': 1.3294199999999994,\n",
       " 'role': 1.3280399999999997,\n",
       " 'brilliant': 1.3100100000000001,\n",
       " 'italian': 1.24688,\n",
       " 'new': 1.2368199999999991,\n",
       " 'man': 1.1952799999999986,\n",
       " 'beautiful': 1.1913199999999997,\n",
       " 'always': 1.1710000000000003,\n",
       " 'enjoy': 1.1691700000000005,\n",
       " 'father': 1.1628599999999998,\n",
       " 'romantic': 1.1478600000000003,\n",
       " 'amazing': 1.1355700000000002}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.wc_X1_diff.items(), key=lambda item: item[1], reverse=True)[:30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see what added most distance when moving from the negative to the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad': 7.070259999999994,\n",
       " 'worst': 4.54303,\n",
       " 'waste': 3.59436,\n",
       " 'money': 2.8272600000000008,\n",
       " 'even': 2.721729999999998,\n",
       " 'stupid': 2.58822,\n",
       " 'awful': 2.4731899999999998,\n",
       " 'ever': 2.3345599999999997,\n",
       " 'boring': 2.2304399999999993,\n",
       " 'movie': 2.1923999999999992,\n",
       " 'terrible': 2.1853499999999992,\n",
       " 'plot': 2.10646,\n",
       " 'poor': 2.1032800000000003,\n",
       " 'guy': 1.963889999999999,\n",
       " 'instead': 1.9381299999999997,\n",
       " 'acting': 1.905740000000001,\n",
       " 'rating': 1.85195,\n",
       " 'nothing': 1.8448299999999993,\n",
       " 'rent': 1.7515500000000002,\n",
       " 'could': 1.7412000000000019,\n",
       " 'made': 1.6352300000000013,\n",
       " 'least': 1.5719700000000003,\n",
       " 'horrible': 1.5380399999999996,\n",
       " 'supposed': 1.4540500000000003,\n",
       " 'say': 1.442960000000001,\n",
       " 'worse': 1.4196200000000003,\n",
       " 'better': 1.4166099999999995,\n",
       " 'hour': 1.348899999999999,\n",
       " 'minute': 1.3478999999999997,\n",
       " 'dull': 1.29528}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wmd_pairs_flow.wc_X2_diff.items(), key=lambda item: item[1], reverse=True)[:30]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at the distances between the two sets by clustering similar words, in order to get a better sense of what kind of \"topics\" that separate them. Each cluster has a weight that matches the sum of the words belonging to that cluster. We choose *n* top clusters to inspect. To make the clusters interpretable, we also represent each of them by *m* keywords, selected based on the cost they individually add between the two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50\n",
    "n_words = 10\n",
    "\n",
    "c1 = output_clusters(wc=wmd_pairs_flow.wc_X1_diff.items(), \n",
    "                     cc=wmd_pairs_flow.cc_X1.items(), \n",
    "                     c2w=cluster2words, \n",
    "                     n_clusters=n_clusters, \n",
    "                     n_words=n_words)\n",
    "c2 = output_clusters(wc=wmd_pairs_flow.wc_X2_diff.items(), \n",
    "                     cc=wmd_pairs_flow.cc_X2.items(), \n",
    "                     c2w=cluster2words, \n",
    "                     n_clusters=n_clusters, \n",
    "                     n_words=n_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive to negative clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>1</th>\n",
       "      <th>21</th>\n",
       "      <th>4</th>\n",
       "      <th>73</th>\n",
       "      <th>65</th>\n",
       "      <th>55</th>\n",
       "      <th>19</th>\n",
       "      <th>69</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>37</th>\n",
       "      <th>80</th>\n",
       "      <th>50</th>\n",
       "      <th>6</th>\n",
       "      <th>35</th>\n",
       "      <th>85</th>\n",
       "      <th>0</th>\n",
       "      <th>11</th>\n",
       "      <th>10</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hope (0.8)</td>\n",
       "      <td>edge (0.96)</td>\n",
       "      <td>still (2.68)</td>\n",
       "      <td>little (1.76)</td>\n",
       "      <td>robin (0.78)</td>\n",
       "      <td>performance (2.43)</td>\n",
       "      <td>later (0.71)</td>\n",
       "      <td>real (0.73)</td>\n",
       "      <td>masterpiece (1.07)</td>\n",
       "      <td>great (3.68)</td>\n",
       "      <td>...</td>\n",
       "      <td>attention (0.69)</td>\n",
       "      <td>best (2.97)</td>\n",
       "      <td>man (1.2)</td>\n",
       "      <td>lovely (0.79)</td>\n",
       "      <td>novel (0.42)</td>\n",
       "      <td>message (0.89)</td>\n",
       "      <td>justice (0.4)</td>\n",
       "      <td>history (0.86)</td>\n",
       "      <td>muresan (0.23)</td>\n",
       "      <td>team (0.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time (0.59)</td>\n",
       "      <td>take (0.89)</td>\n",
       "      <td>enjoy (1.17)</td>\n",
       "      <td>nice (0.66)</td>\n",
       "      <td>joe (0.69)</td>\n",
       "      <td>role (1.33)</td>\n",
       "      <td>last (0.66)</td>\n",
       "      <td>major (0.63)</td>\n",
       "      <td>genius (0.93)</td>\n",
       "      <td>excellent (2.31)</td>\n",
       "      <td>...</td>\n",
       "      <td>without (0.33)</td>\n",
       "      <td>favorite (1.89)</td>\n",
       "      <td>father (1.16)</td>\n",
       "      <td>sexy (0.54)</td>\n",
       "      <td>hamlet (0.41)</td>\n",
       "      <td>lesson (0.56)</td>\n",
       "      <td>seek (0.34)</td>\n",
       "      <td>western (0.37)</td>\n",
       "      <td>gheorghe (0.17)</td>\n",
       "      <td>battle (0.47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wish (0.58)</td>\n",
       "      <td>keep (0.84)</td>\n",
       "      <td>definitely (1.03)</td>\n",
       "      <td>although (0.64)</td>\n",
       "      <td>john (0.65)</td>\n",
       "      <td>play (0.72)</td>\n",
       "      <td>remember (0.46)</td>\n",
       "      <td>different (0.57)</td>\n",
       "      <td>true (0.75)</td>\n",
       "      <td>wonderful (1.89)</td>\n",
       "      <td>...</td>\n",
       "      <td>level (0.31)</td>\n",
       "      <td>greatest (0.84)</td>\n",
       "      <td>lover (0.3)</td>\n",
       "      <td>lady (0.36)</td>\n",
       "      <td>adaptation (0.37)</td>\n",
       "      <td>documentary (0.43)</td>\n",
       "      <td>solution (0.32)</td>\n",
       "      <td>community (0.27)</td>\n",
       "      <td>bonham (0.13)</td>\n",
       "      <td>fighting (0.26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doubt (0.51)</td>\n",
       "      <td>side (0.56)</td>\n",
       "      <td>feel (0.84)</td>\n",
       "      <td>part (0.58)</td>\n",
       "      <td>brown (0.6)</td>\n",
       "      <td>supporting (0.64)</td>\n",
       "      <td>took (0.44)</td>\n",
       "      <td>question (0.52)</td>\n",
       "      <td>work (0.73)</td>\n",
       "      <td>perfect (1.43)</td>\n",
       "      <td>...</td>\n",
       "      <td>confidence (0.23)</td>\n",
       "      <td>favourite (0.77)</td>\n",
       "      <td>caring (0.26)</td>\n",
       "      <td>seductive (0.31)</td>\n",
       "      <td>literature (0.28)</td>\n",
       "      <td>issue (0.36)</td>\n",
       "      <td>dealing (0.25)</td>\n",
       "      <td>folk (0.26)</td>\n",
       "      <td>liebmann (0.11)</td>\n",
       "      <td>member (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whether (0.36)</td>\n",
       "      <td>behind (0.39)</td>\n",
       "      <td>fan (0.82)</td>\n",
       "      <td>plus (0.55)</td>\n",
       "      <td>jim (0.57)</td>\n",
       "      <td>playing (0.52)</td>\n",
       "      <td>forgotten (0.41)</td>\n",
       "      <td>important (0.42)</td>\n",
       "      <td>cinema (0.71)</td>\n",
       "      <td>brilliant (1.31)</td>\n",
       "      <td>...</td>\n",
       "      <td>immense (0.22)</td>\n",
       "      <td>finest (0.5)</td>\n",
       "      <td>realizes (0.2)</td>\n",
       "      <td>elvira (0.26)</td>\n",
       "      <td>faithful (0.24)</td>\n",
       "      <td>gay (0.31)</td>\n",
       "      <td>authority (0.22)</td>\n",
       "      <td>depicting (0.25)</td>\n",
       "      <td>taft (0.11)</td>\n",
       "      <td>leader (0.24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>matter (0.35)</td>\n",
       "      <td>move (0.39)</td>\n",
       "      <td>enjoyed (0.66)</td>\n",
       "      <td>typical (0.5)</td>\n",
       "      <td>jones (0.55)</td>\n",
       "      <td>talented (0.47)</td>\n",
       "      <td>june (0.34)</td>\n",
       "      <td>minor (0.34)</td>\n",
       "      <td>art (0.61)</td>\n",
       "      <td>beautiful (1.19)</td>\n",
       "      <td>...</td>\n",
       "      <td>physical (0.17)</td>\n",
       "      <td>stupidest (0.25)</td>\n",
       "      <td>troubled (0.17)</td>\n",
       "      <td>shy (0.24)</td>\n",
       "      <td>accurate (0.24)</td>\n",
       "      <td>society (0.31)</td>\n",
       "      <td>dealt (0.22)</td>\n",
       "      <td>bend (0.25)</td>\n",
       "      <td>beckham (0.1)</td>\n",
       "      <td>rescue (0.23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>automatically (0.29)</td>\n",
       "      <td>break (0.38)</td>\n",
       "      <td>worth (0.63)</td>\n",
       "      <td>course (0.43)</td>\n",
       "      <td>lee (0.52)</td>\n",
       "      <td>caine (0.46)</td>\n",
       "      <td>hit (0.33)</td>\n",
       "      <td>notice (0.31)</td>\n",
       "      <td>picture (0.6)</td>\n",
       "      <td>amazing (1.14)</td>\n",
       "      <td>...</td>\n",
       "      <td>skill (0.17)</td>\n",
       "      <td>absolute (0.21)</td>\n",
       "      <td>engaged (0.16)</td>\n",
       "      <td>handsome (0.23)</td>\n",
       "      <td>biography (0.21)</td>\n",
       "      <td>stance (0.25)</td>\n",
       "      <td>learning (0.17)</td>\n",
       "      <td>honor (0.24)</td>\n",
       "      <td>welker (0.09)</td>\n",
       "      <td>illegal (0.22)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anywhere (0.28)</td>\n",
       "      <td>run (0.35)</td>\n",
       "      <td>may (0.42)</td>\n",
       "      <td>plenty (0.33)</td>\n",
       "      <td>mickey (0.5)</td>\n",
       "      <td>flynn (0.36)</td>\n",
       "      <td>ran (0.24)</td>\n",
       "      <td>missing (0.23)</td>\n",
       "      <td>gem (0.57)</td>\n",
       "      <td>incredible (1.06)</td>\n",
       "      <td>...</td>\n",
       "      <td>satisfaction (0.16)</td>\n",
       "      <td>arguably (0.21)</td>\n",
       "      <td>coward (0.16)</td>\n",
       "      <td>distress (0.18)</td>\n",
       "      <td>page (0.19)</td>\n",
       "      <td>cultural (0.25)</td>\n",
       "      <td>fearing (0.16)</td>\n",
       "      <td>taught (0.22)</td>\n",
       "      <td>obv (0.09)</td>\n",
       "      <td>men (0.18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>another (0.22)</td>\n",
       "      <td>come (0.25)</td>\n",
       "      <td>experience (0.36)</td>\n",
       "      <td>though (0.28)</td>\n",
       "      <td>kevin (0.48)</td>\n",
       "      <td>portrayal (0.36)</td>\n",
       "      <td>started (0.23)</td>\n",
       "      <td>included (0.22)</td>\n",
       "      <td>era (0.38)</td>\n",
       "      <td>superb (0.94)</td>\n",
       "      <td>...</td>\n",
       "      <td>difficulty (0.15)</td>\n",
       "      <td>coolest (0.13)</td>\n",
       "      <td>learns (0.16)</td>\n",
       "      <td>gorgeous (0.17)</td>\n",
       "      <td>poem (0.17)</td>\n",
       "      <td>social (0.22)</td>\n",
       "      <td>support (0.16)</td>\n",
       "      <td>common (0.2)</td>\n",
       "      <td>orhan (0.08)</td>\n",
       "      <td>union (0.17)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>one (0.21)</td>\n",
       "      <td>hold (0.24)</td>\n",
       "      <td>taste (0.29)</td>\n",
       "      <td>filled (0.25)</td>\n",
       "      <td>robert (0.47)</td>\n",
       "      <td>believable (0.34)</td>\n",
       "      <td>july (0.22)</td>\n",
       "      <td>note (0.22)</td>\n",
       "      <td>hitchcock (0.35)</td>\n",
       "      <td>fantastic (0.81)</td>\n",
       "      <td>...</td>\n",
       "      <td>accuracy (0.11)</td>\n",
       "      <td>undoubtedly (0.05)</td>\n",
       "      <td>whose (0.15)</td>\n",
       "      <td>heroine (0.15)</td>\n",
       "      <td>vonnegut (0.16)</td>\n",
       "      <td>subject (0.2)</td>\n",
       "      <td>duty (0.15)</td>\n",
       "      <td>opposed (0.19)</td>\n",
       "      <td>antic (0.08)</td>\n",
       "      <td>training (0.17)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     24             1                  21               4   \\\n",
       "0            hope (0.8)    edge (0.96)       still (2.68)    little (1.76)   \n",
       "1           time (0.59)    take (0.89)       enjoy (1.17)      nice (0.66)   \n",
       "2           wish (0.58)    keep (0.84)  definitely (1.03)  although (0.64)   \n",
       "3          doubt (0.51)    side (0.56)        feel (0.84)      part (0.58)   \n",
       "4        whether (0.36)  behind (0.39)         fan (0.82)      plus (0.55)   \n",
       "5         matter (0.35)    move (0.39)     enjoyed (0.66)    typical (0.5)   \n",
       "6  automatically (0.29)   break (0.38)       worth (0.63)    course (0.43)   \n",
       "7       anywhere (0.28)     run (0.35)         may (0.42)    plenty (0.33)   \n",
       "8        another (0.22)    come (0.25)  experience (0.36)    though (0.28)   \n",
       "9            one (0.21)    hold (0.24)       taste (0.29)    filled (0.25)   \n",
       "\n",
       "              73                  65                55                19  \\\n",
       "0   robin (0.78)  performance (2.43)      later (0.71)       real (0.73)   \n",
       "1     joe (0.69)         role (1.33)       last (0.66)      major (0.63)   \n",
       "2    john (0.65)         play (0.72)   remember (0.46)  different (0.57)   \n",
       "3    brown (0.6)   supporting (0.64)       took (0.44)   question (0.52)   \n",
       "4     jim (0.57)      playing (0.52)  forgotten (0.41)  important (0.42)   \n",
       "5   jones (0.55)     talented (0.47)       june (0.34)      minor (0.34)   \n",
       "6     lee (0.52)        caine (0.46)        hit (0.33)     notice (0.31)   \n",
       "7   mickey (0.5)        flynn (0.36)        ran (0.24)    missing (0.23)   \n",
       "8   kevin (0.48)    portrayal (0.36)    started (0.23)   included (0.22)   \n",
       "9  robert (0.47)   believable (0.34)       july (0.22)       note (0.22)   \n",
       "\n",
       "                   69                 39  ...                   37  \\\n",
       "0  masterpiece (1.07)       great (3.68)  ...     attention (0.69)   \n",
       "1       genius (0.93)   excellent (2.31)  ...       without (0.33)   \n",
       "2         true (0.75)   wonderful (1.89)  ...         level (0.31)   \n",
       "3         work (0.73)     perfect (1.43)  ...    confidence (0.23)   \n",
       "4       cinema (0.71)   brilliant (1.31)  ...       immense (0.22)   \n",
       "5          art (0.61)   beautiful (1.19)  ...      physical (0.17)   \n",
       "6       picture (0.6)     amazing (1.14)  ...         skill (0.17)   \n",
       "7          gem (0.57)  incredible (1.06)  ...  satisfaction (0.16)   \n",
       "8          era (0.38)      superb (0.94)  ...    difficulty (0.15)   \n",
       "9    hitchcock (0.35)   fantastic (0.81)  ...      accuracy (0.11)   \n",
       "\n",
       "                   80               50                6                  35  \\\n",
       "0         best (2.97)        man (1.2)     lovely (0.79)       novel (0.42)   \n",
       "1     favorite (1.89)    father (1.16)       sexy (0.54)      hamlet (0.41)   \n",
       "2     greatest (0.84)      lover (0.3)       lady (0.36)  adaptation (0.37)   \n",
       "3    favourite (0.77)    caring (0.26)  seductive (0.31)  literature (0.28)   \n",
       "4        finest (0.5)   realizes (0.2)     elvira (0.26)    faithful (0.24)   \n",
       "5    stupidest (0.25)  troubled (0.17)        shy (0.24)    accurate (0.24)   \n",
       "6     absolute (0.21)   engaged (0.16)   handsome (0.23)   biography (0.21)   \n",
       "7     arguably (0.21)    coward (0.16)   distress (0.18)        page (0.19)   \n",
       "8      coolest (0.13)    learns (0.16)   gorgeous (0.17)        poem (0.17)   \n",
       "9  undoubtedly (0.05)     whose (0.15)    heroine (0.15)    vonnegut (0.16)   \n",
       "\n",
       "                   85                0                 11               10  \\\n",
       "0      message (0.89)     justice (0.4)    history (0.86)   muresan (0.23)   \n",
       "1       lesson (0.56)       seek (0.34)    western (0.37)  gheorghe (0.17)   \n",
       "2  documentary (0.43)   solution (0.32)  community (0.27)    bonham (0.13)   \n",
       "3        issue (0.36)    dealing (0.25)       folk (0.26)  liebmann (0.11)   \n",
       "4          gay (0.31)  authority (0.22)  depicting (0.25)      taft (0.11)   \n",
       "5      society (0.31)      dealt (0.22)       bend (0.25)    beckham (0.1)   \n",
       "6       stance (0.25)   learning (0.17)      honor (0.24)    welker (0.09)   \n",
       "7     cultural (0.25)    fearing (0.16)     taught (0.22)       obv (0.09)   \n",
       "8       social (0.22)    support (0.16)      common (0.2)     orhan (0.08)   \n",
       "9       subject (0.2)       duty (0.15)    opposed (0.19)     antic (0.08)   \n",
       "\n",
       "                34  \n",
       "0       team (0.6)  \n",
       "1    battle (0.47)  \n",
       "2  fighting (0.26)  \n",
       "3    member (0.24)  \n",
       "4    leader (0.24)  \n",
       "5    rescue (0.23)  \n",
       "6   illegal (0.22)  \n",
       "7       men (0.18)  \n",
       "8     union (0.17)  \n",
       "9  training (0.17)  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative to positive clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>24</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>88</th>\n",
       "      <th>21</th>\n",
       "      <th>15</th>\n",
       "      <th>55</th>\n",
       "      <th>19</th>\n",
       "      <th>75</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>44</th>\n",
       "      <th>6</th>\n",
       "      <th>89</th>\n",
       "      <th>86</th>\n",
       "      <th>93</th>\n",
       "      <th>13</th>\n",
       "      <th>79</th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>even (2.72)</td>\n",
       "      <td>instead (1.94)</td>\n",
       "      <td>go (0.74)</td>\n",
       "      <td>got (1.28)</td>\n",
       "      <td>enough (1.08)</td>\n",
       "      <td>bad (7.07)</td>\n",
       "      <td>made (1.64)</td>\n",
       "      <td>case (1.24)</td>\n",
       "      <td>seemed (1.23)</td>\n",
       "      <td>plot (2.11)</td>\n",
       "      <td>...</td>\n",
       "      <td>sex (1.0)</td>\n",
       "      <td>woman (0.48)</td>\n",
       "      <td>morning (0.29)</td>\n",
       "      <td>earth (0.68)</td>\n",
       "      <td>angst (0.38)</td>\n",
       "      <td>suddenly (0.39)</td>\n",
       "      <td>jason (0.42)</td>\n",
       "      <td>receiving (0.4)</td>\n",
       "      <td>bunch (0.78)</td>\n",
       "      <td>guy (1.96)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie (2.19)</td>\n",
       "      <td>nothing (1.84)</td>\n",
       "      <td>getting (0.61)</td>\n",
       "      <td>really (1.27)</td>\n",
       "      <td>expect (0.9)</td>\n",
       "      <td>stupid (2.59)</td>\n",
       "      <td>went (1.03)</td>\n",
       "      <td>fact (0.67)</td>\n",
       "      <td>bored (1.17)</td>\n",
       "      <td>action (1.16)</td>\n",
       "      <td>...</td>\n",
       "      <td>violence (0.7)</td>\n",
       "      <td>girl (0.44)</td>\n",
       "      <td>surf (0.19)</td>\n",
       "      <td>destroy (0.31)</td>\n",
       "      <td>mental (0.21)</td>\n",
       "      <td>cure (0.29)</td>\n",
       "      <td>sue (0.32)</td>\n",
       "      <td>saving (0.21)</td>\n",
       "      <td>looking (0.5)</td>\n",
       "      <td>ugly (0.38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>could (1.74)</td>\n",
       "      <td>pretty (0.99)</td>\n",
       "      <td>stay (0.58)</td>\n",
       "      <td>ok (1.09)</td>\n",
       "      <td>watching (0.8)</td>\n",
       "      <td>awful (2.47)</td>\n",
       "      <td>seen (0.68)</td>\n",
       "      <td>problem (0.67)</td>\n",
       "      <td>hated (0.68)</td>\n",
       "      <td>lack (1.07)</td>\n",
       "      <td>...</td>\n",
       "      <td>nudity (0.64)</td>\n",
       "      <td>female (0.33)</td>\n",
       "      <td>dinner (0.19)</td>\n",
       "      <td>machine (0.25)</td>\n",
       "      <td>existence (0.17)</td>\n",
       "      <td>mad (0.28)</td>\n",
       "      <td>charlie (0.31)</td>\n",
       "      <td>task (0.19)</td>\n",
       "      <td>drink (0.36)</td>\n",
       "      <td>santa (0.32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>say (1.44)</td>\n",
       "      <td>whole (0.98)</td>\n",
       "      <td>next (0.54)</td>\n",
       "      <td>maybe (1.07)</td>\n",
       "      <td>disappointed (0.76)</td>\n",
       "      <td>terrible (2.19)</td>\n",
       "      <td>ended (0.59)</td>\n",
       "      <td>apparently (0.49)</td>\n",
       "      <td>left (0.59)</td>\n",
       "      <td>viewer (0.63)</td>\n",
       "      <td>...</td>\n",
       "      <td>porn (0.52)</td>\n",
       "      <td>lesbian (0.32)</td>\n",
       "      <td>theatre (0.17)</td>\n",
       "      <td>size (0.25)</td>\n",
       "      <td>imaginary (0.17)</td>\n",
       "      <td>becomes (0.26)</td>\n",
       "      <td>joey (0.23)</td>\n",
       "      <td>severe (0.15)</td>\n",
       "      <td>drinking (0.26)</td>\n",
       "      <td>wannabe (0.31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better (1.42)</td>\n",
       "      <td>rest (0.74)</td>\n",
       "      <td>get (0.49)</td>\n",
       "      <td>thing (1.04)</td>\n",
       "      <td>bore (0.64)</td>\n",
       "      <td>poor (2.1)</td>\n",
       "      <td>gone (0.56)</td>\n",
       "      <td>point (0.46)</td>\n",
       "      <td>confused (0.53)</td>\n",
       "      <td>whatsoever (0.52)</td>\n",
       "      <td>...</td>\n",
       "      <td>disgusting (0.51)</td>\n",
       "      <td>hot (0.3)</td>\n",
       "      <td>club (0.12)</td>\n",
       "      <td>serum (0.25)</td>\n",
       "      <td>surrounding (0.14)</td>\n",
       "      <td>happens (0.2)</td>\n",
       "      <td>andy (0.21)</td>\n",
       "      <td>surround (0.14)</td>\n",
       "      <td>candy (0.2)</td>\n",
       "      <td>spoiled (0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>anything (1.16)</td>\n",
       "      <td>premise (0.73)</td>\n",
       "      <td>start (0.47)</td>\n",
       "      <td>mean (0.95)</td>\n",
       "      <td>otherwise (0.58)</td>\n",
       "      <td>horrible (1.54)</td>\n",
       "      <td>finished (0.55)</td>\n",
       "      <td>clue (0.46)</td>\n",
       "      <td>disappointment (0.49)</td>\n",
       "      <td>explanation (0.44)</td>\n",
       "      <td>...</td>\n",
       "      <td>gratuitous (0.34)</td>\n",
       "      <td>topless (0.27)</td>\n",
       "      <td>rave (0.12)</td>\n",
       "      <td>computer (0.23)</td>\n",
       "      <td>precisely (0.13)</td>\n",
       "      <td>whale (0.19)</td>\n",
       "      <td>matt (0.15)</td>\n",
       "      <td>trusted (0.14)</td>\n",
       "      <td>beating (0.19)</td>\n",
       "      <td>idiot (0.26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>something (0.99)</td>\n",
       "      <td>basically (0.7)</td>\n",
       "      <td>back (0.42)</td>\n",
       "      <td>going (0.84)</td>\n",
       "      <td>skip (0.48)</td>\n",
       "      <td>worse (1.42)</td>\n",
       "      <td>fox (0.54)</td>\n",
       "      <td>particular (0.34)</td>\n",
       "      <td>looked (0.48)</td>\n",
       "      <td>development (0.43)</td>\n",
       "      <td>...</td>\n",
       "      <td>extreme (0.32)</td>\n",
       "      <td>babe (0.21)</td>\n",
       "      <td>premiere (0.09)</td>\n",
       "      <td>facility (0.23)</td>\n",
       "      <td>traumatic (0.11)</td>\n",
       "      <td>insane (0.18)</td>\n",
       "      <td>kathryn (0.15)</td>\n",
       "      <td>cheat (0.13)</td>\n",
       "      <td>smoking (0.17)</td>\n",
       "      <td>stereotypical (0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>else (0.97)</td>\n",
       "      <td>unfortunately (0.69)</td>\n",
       "      <td>open (0.41)</td>\n",
       "      <td>oh (0.79)</td>\n",
       "      <td>faint (0.32)</td>\n",
       "      <td>cheap (1.03)</td>\n",
       "      <td>came (0.54)</td>\n",
       "      <td>main (0.31)</td>\n",
       "      <td>expected (0.45)</td>\n",
       "      <td>lacked (0.41)</td>\n",
       "      <td>...</td>\n",
       "      <td>crude (0.3)</td>\n",
       "      <td>psychic (0.2)</td>\n",
       "      <td>school (0.09)</td>\n",
       "      <td>enterprise (0.22)</td>\n",
       "      <td>foundation (0.1)</td>\n",
       "      <td>becoming (0.16)</td>\n",
       "      <td>nephew (0.14)</td>\n",
       "      <td>resource (0.12)</td>\n",
       "      <td>toilet (0.17)</td>\n",
       "      <td>goofy (0.21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>idea (0.96)</td>\n",
       "      <td>complete (0.66)</td>\n",
       "      <td>finish (0.32)</td>\n",
       "      <td>suck (0.75)</td>\n",
       "      <td>insomnia (0.2)</td>\n",
       "      <td>lame (0.9)</td>\n",
       "      <td>first (0.44)</td>\n",
       "      <td>explained (0.26)</td>\n",
       "      <td>brought (0.32)</td>\n",
       "      <td>zero (0.39)</td>\n",
       "      <td>...</td>\n",
       "      <td>nasty (0.28)</td>\n",
       "      <td>chick (0.2)</td>\n",
       "      <td>ceremony (0.03)</td>\n",
       "      <td>mass (0.21)</td>\n",
       "      <td>observes (0.1)</td>\n",
       "      <td>appears (0.16)</td>\n",
       "      <td>adam (0.13)</td>\n",
       "      <td>protocol (0.12)</td>\n",
       "      <td>wet (0.17)</td>\n",
       "      <td>freak (0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unless (0.92)</td>\n",
       "      <td>redeeming (0.61)</td>\n",
       "      <td>sign (0.3)</td>\n",
       "      <td>spoiler (0.7)</td>\n",
       "      <td>see (0.15)</td>\n",
       "      <td>badly (0.83)</td>\n",
       "      <td>episode (0.39)</td>\n",
       "      <td>reference (0.25)</td>\n",
       "      <td>ruined (0.32)</td>\n",
       "      <td>motivation (0.38)</td>\n",
       "      <td>...</td>\n",
       "      <td>rape (0.28)</td>\n",
       "      <td>plump (0.18)</td>\n",
       "      <td>birthday (0.03)</td>\n",
       "      <td>large (0.18)</td>\n",
       "      <td>study (0.09)</td>\n",
       "      <td>supposedly (0.16)</td>\n",
       "      <td>uncle (0.11)</td>\n",
       "      <td>drug (0.12)</td>\n",
       "      <td>vomiting (0.17)</td>\n",
       "      <td>nut (0.19)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 24                    4               1              88  \\\n",
       "0       even (2.72)        instead (1.94)       go (0.74)     got (1.28)   \n",
       "1      movie (2.19)        nothing (1.84)  getting (0.61)  really (1.27)   \n",
       "2      could (1.74)         pretty (0.99)     stay (0.58)      ok (1.09)   \n",
       "3        say (1.44)          whole (0.98)     next (0.54)   maybe (1.07)   \n",
       "4     better (1.42)           rest (0.74)      get (0.49)   thing (1.04)   \n",
       "5   anything (1.16)        premise (0.73)    start (0.47)    mean (0.95)   \n",
       "6  something (0.99)       basically (0.7)     back (0.42)   going (0.84)   \n",
       "7       else (0.97)  unfortunately (0.69)     open (0.41)      oh (0.79)   \n",
       "8       idea (0.96)       complete (0.66)   finish (0.32)    suck (0.75)   \n",
       "9     unless (0.92)      redeeming (0.61)      sign (0.3)  spoiler (0.7)   \n",
       "\n",
       "                    21               15               55                 19  \\\n",
       "0        enough (1.08)       bad (7.07)      made (1.64)        case (1.24)   \n",
       "1         expect (0.9)    stupid (2.59)      went (1.03)        fact (0.67)   \n",
       "2       watching (0.8)     awful (2.47)      seen (0.68)     problem (0.67)   \n",
       "3  disappointed (0.76)  terrible (2.19)     ended (0.59)  apparently (0.49)   \n",
       "4          bore (0.64)       poor (2.1)      gone (0.56)       point (0.46)   \n",
       "5     otherwise (0.58)  horrible (1.54)  finished (0.55)        clue (0.46)   \n",
       "6          skip (0.48)     worse (1.42)       fox (0.54)  particular (0.34)   \n",
       "7         faint (0.32)     cheap (1.03)      came (0.54)        main (0.31)   \n",
       "8       insomnia (0.2)       lame (0.9)     first (0.44)   explained (0.26)   \n",
       "9           see (0.15)     badly (0.83)   episode (0.39)   reference (0.25)   \n",
       "\n",
       "                      75                  14  ...                 44  \\\n",
       "0          seemed (1.23)         plot (2.11)  ...          sex (1.0)   \n",
       "1           bored (1.17)       action (1.16)  ...     violence (0.7)   \n",
       "2           hated (0.68)         lack (1.07)  ...      nudity (0.64)   \n",
       "3            left (0.59)       viewer (0.63)  ...        porn (0.52)   \n",
       "4        confused (0.53)   whatsoever (0.52)  ...  disgusting (0.51)   \n",
       "5  disappointment (0.49)  explanation (0.44)  ...  gratuitous (0.34)   \n",
       "6          looked (0.48)  development (0.43)  ...     extreme (0.32)   \n",
       "7        expected (0.45)       lacked (0.41)  ...        crude (0.3)   \n",
       "8         brought (0.32)         zero (0.39)  ...       nasty (0.28)   \n",
       "9          ruined (0.32)   motivation (0.38)  ...        rape (0.28)   \n",
       "\n",
       "               6                89                 86                  93  \\\n",
       "0    woman (0.48)   morning (0.29)       earth (0.68)        angst (0.38)   \n",
       "1     girl (0.44)      surf (0.19)     destroy (0.31)       mental (0.21)   \n",
       "2   female (0.33)    dinner (0.19)     machine (0.25)    existence (0.17)   \n",
       "3  lesbian (0.32)   theatre (0.17)        size (0.25)    imaginary (0.17)   \n",
       "4       hot (0.3)      club (0.12)       serum (0.25)  surrounding (0.14)   \n",
       "5  topless (0.27)      rave (0.12)    computer (0.23)    precisely (0.13)   \n",
       "6     babe (0.21)  premiere (0.09)    facility (0.23)    traumatic (0.11)   \n",
       "7   psychic (0.2)    school (0.09)  enterprise (0.22)    foundation (0.1)   \n",
       "8     chick (0.2)  ceremony (0.03)        mass (0.21)      observes (0.1)   \n",
       "9    plump (0.18)  birthday (0.03)       large (0.18)        study (0.09)   \n",
       "\n",
       "                  13              79               0                7   \\\n",
       "0    suddenly (0.39)    jason (0.42)  receiving (0.4)     bunch (0.78)   \n",
       "1        cure (0.29)      sue (0.32)    saving (0.21)    looking (0.5)   \n",
       "2         mad (0.28)  charlie (0.31)      task (0.19)     drink (0.36)   \n",
       "3     becomes (0.26)     joey (0.23)    severe (0.15)  drinking (0.26)   \n",
       "4      happens (0.2)     andy (0.21)  surround (0.14)      candy (0.2)   \n",
       "5       whale (0.19)     matt (0.15)   trusted (0.14)   beating (0.19)   \n",
       "6      insane (0.18)  kathryn (0.15)     cheat (0.13)   smoking (0.17)   \n",
       "7    becoming (0.16)   nephew (0.14)  resource (0.12)    toilet (0.17)   \n",
       "8     appears (0.16)     adam (0.13)  protocol (0.12)       wet (0.17)   \n",
       "9  supposedly (0.16)    uncle (0.11)      drug (0.12)  vomiting (0.17)   \n",
       "\n",
       "                     52  \n",
       "0            guy (1.96)  \n",
       "1           ugly (0.38)  \n",
       "2          santa (0.32)  \n",
       "3        wannabe (0.31)  \n",
       "4         spoiled (0.3)  \n",
       "5          idiot (0.26)  \n",
       "6  stereotypical (0.21)  \n",
       "7          goofy (0.21)  \n",
       "8           freak (0.2)  \n",
       "9            nut (0.19)  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Many-to-many WMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a first attempt to do the flows from words between many documents, without first filtering using Gale-Shapeley. However, this proved too inefficient. As you can see looking at the CPU times, it is very slow even with extremely small samples and the time complexity is quadratic (or worse?), meaning it rapidly gets even worse as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 12.7 s, total: 2min 1s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%time m2m_distances = WMDManyToMany(pos_docs[:20], neg_docs[:20],E,idx2word).get_distances(return_flow = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 13.5 s, total: 2min 5s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%time m2m_distances_flow, wc_X1, wc_X2 = WMDManyToMany(pos_docs[:20],neg_docs[:20],E,idx2word).get_distances(return_flow = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'karen': 8.69223,\n",
       " 'wrenching': 8.31882,\n",
       " 'carpenter': 7.468960000000001,\n",
       " 'laughter': 7.467879999999999,\n",
       " 'liked': 6.864090000000003,\n",
       " 'mom': 6.791519999999999,\n",
       " 'gut': 6.759419999999999,\n",
       " 'love': 6.551409999999997,\n",
       " 'camp': 6.533080000000001,\n",
       " 'hr': 6.1393699999999995}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wc_X1.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hopper': 8.372459999999998,\n",
       " 'jake': 7.63837,\n",
       " 'movie': 7.267059999999995,\n",
       " 'film': 6.936379999999998,\n",
       " 'shakespeare': 5.99276,\n",
       " 'oddness': 5.53033,\n",
       " 'terrible': 4.943440000000001,\n",
       " 'parent': 4.751790000000001,\n",
       " 'actor': 4.672620000000001,\n",
       " 'bad': 4.430020000000002}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(wc_X2.items(), key=lambda item: item[1], reverse=True)[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-fwmd",
   "language": "python",
   "name": "venv-fwmd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
